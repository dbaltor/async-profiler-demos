<!DOCTYPE html>
<html lang="en-US"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[Java][Profiling] Async-profiler - manual by use cases | JVM/Java profiling and tuning</title>
<meta name="generator" content="Jekyll v3.9.3">
<meta property="og:title" content="[Java][Profiling] Async-profiler - manual by use cases">
<meta property="og:locale" content="en_US">
<meta name="description" content="[Java][Profiling] Async-profiler - manual by use cases">
<meta property="og:description" content="[Java][Profiling] Async-profiler - manual by use cases">
<link rel="canonical" href="https://krzysztofslusarski.github.io/2022/12/12/async-manual.html">
<meta property="og:url" content="https://krzysztofslusarski.github.io/2022/12/12/async-manual.html">
<meta property="og:site_name" content="JVM/Java profiling and tuning">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2022-12-12T01:51:30+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="[Java][Profiling] Async-profiler - manual by use cases">
<script async="" src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/analytics.js"></script><script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-12-12T01:51:30+00:00","datePublished":"2022-12-12T01:51:30+00:00","description":"[Java][Profiling] Async-profiler - manual by use cases","headline":"[Java][Profiling] Async-profiler - manual by use cases","mainEntityOfPage":{"@type":"WebPage","@id":"https://krzysztofslusarski.github.io/2022/12/12/async-manual.html"},"url":"https://krzysztofslusarski.github.io/2022/12/12/async-manual.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com/">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&amp;display=swap" as="style" type="text/css" crossorigin="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/style.css">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-183103577-1', 'auto');
    ga('send', 'pageview');
  </script>



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  <link href="data:text/css,%3Ais(%5Bid*%3D'google_ads_iframe'%5D%2C%5Bid*%3D'taboola-'%5D%2C.taboolaHeight%2C.taboola-placeholder%2C%23top-ad%2C%23credential_picker_container%2C%23credentials-picker-container%2C%23credential_picker_iframe%2C%5Bid*%3D'google-one-tap-iframe'%5D%2C%23google-one-tap-popup-container%2C.google-one-tap__module%2C.google-one-tap-modal-div%2C%23amp_floatingAdDiv%2C%23ez-content-blocker-container)%20%7Bdisplay%3Anone!important%3Bmin-height%3A0!important%3Bheight%3A0!important%3B%7D" rel="stylesheet" type="text/css"></head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">[Java][Profiling] Async-profiler - manual by use cases</h1>
      <h2 class="project-tagline">Just a homepage</h2>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="javaprofiling-async-profiler---manual-by-use-cases">[Java][Profiling] Async-profiler - manual by use cases</h1>

<p>This blog post contains examples of async-profiler usages that I have found helpful in my job.
Some content of this post is copy-pasted from previous entries, as I just wanted to avoid unnecessary
jumps between articles.</p>

<p>The goal of that post is to give examples. It’s not a replacement for the project <a href="https://github.com/jvm-profiling-tools/async-profiler#readme" target="_blank">README</a>. I advise you to read it, as it tells you how to obtain async-profiler binaries and more.</p>

<p>All the examples that you are going to see here are synthetic reproductions of real-world 
problems that I solved during my career. Even if some examples look like “it’s too stupid
to happen anywhere,” well, it isn’t.</p>

<p>That post will be maintained. Whenever I find a new use case that I think is worth sharing, I will update
this post.</p>

<ul>
  <li><a href="#change-log">Change log</a></li>
  <li><a href="#acknowledgments">Acknowledgments</a></li>
  <li><a href="#profiled-application">Profiled application</a></li>
  <li><a href="#how-to">How to run an async-profiler</a>
    <ul>
      <li><a href="#how-to-cl">Command line</a></li>
      <li><a href="#how-to-jvm">During JVM startup</a></li>
      <li><a href="#how-to-java">From Java API</a></li>
      <li><a href="#how-to-jmh">From JMH benchmark</a></li>
      <li><a href="#how-to-apl">AP-Loader</a></li>
      <li><a href="#how-to-idea">IntelliJ Idea</a></li>
    </ul>
  </li>
  <li><a href="#out">Output formats</a></li>
  <li><a href="#flames">Flame graphs</a></li>
  <li><a href="#basic-resources">Basic resources profiling</a>
    <ul>
      <li><a href="#wall">Wall-clock</a></li>
      <li><a href="#wall-filter">Wall-clock - filtering</a></li>
      <li><a href="#cpu-easy">CPU - easy-peasy</a></li>
      <li><a href="#cpu-hard">CPU - a bit harder</a></li>
      <li><a href="#alloc">Allocation</a></li>
      <li><a href="#alloc-ha">Allocation - humongous objects</a></li>
      <li><a href="#alloc-live">Allocation - live objects</a></li>
      <li><a href="#locks">Locks</a></li>
    </ul>
  </li>
  <li><a href="#tts">Time to safepoint</a></li>
  <li><a href="#methods">Methods profiling</a></li>
  <li><a href="#methods-native">Native functions</a>
    <ul>
      <li><a href="#methods-ex">Exceptions</a></li>
      <li><a href="#methods-g1ha">G1GC humongous allocation</a></li>
      <li><a href="#methods-thread">Thread start</a></li>
      <li><a href="#methods-classes">Class loading</a></li>
    </ul>
  </li>
  <li><a href="#perf">Perf events</a>
    <ul>
      <li><a href="#perf-cache">Cache misses</a></li>
      <li><a href="#perf-pf">Page faults</a></li>
      <li><a href="#perf-cycles">Cycles</a></li>
    </ul>
  </li>
  <li><a href="#single-req">Filtering single request</a>
    <ul>
      <li><a href="#single-req-why">Why aggregated results are not enough</a></li>
      <li><a href="#single-req-dns">Real life example - DNS</a></li>
    </ul>
  </li>
  <li><a href="#continuous">Continuous profiling</a>
    <ul>
      <li><a href="#continuous-cli}">Command line</a></li>
      <li><a href="#continuous-java">Java</a></li>
      <li><a href="#continuous-spring">Spring Boot</a></li>
    </ul>
  </li>
  <li><a href="#context-id">Contextual profiling</a>
    <ul>
      <li><a href="#context-id-spring">Spring Boot microservices</a></li>
      <li><a href="#context-id-hz">Distributed systems</a></li>
    </ul>
  </li>
  <li><a href="#stability">Stability</a></li>
  <li><a href="#overhead">Overhead</a></li>
  <li><a href="#random">Random thoughts</a></li>
</ul>

<h2 id="change-log">Change log</h2>

<ul>
  <li>2022-12-16 - Initial version</li>
</ul>

<h2 id="acknowledgments">Acknowledgments</h2>

<p>I would like to say thank you to <a href="https://twitter.com/AndreiPangin" target="_blank">Andrei Pangin</a>
(<a href="https://lightrun.com/" target="_blank">Lightrun</a>)
for all the work he did to create async-profiler and for
his time and remarks on that article,
<a href="https://twitter.com/parttimen3rd" target="_blank">Johannes Bechberger</a> (<a href="https://sapmachine.io/" target="_blank">SapMachine team</a> at <a href="https://sap.com/" target="_blank">SAP</a>) for all the work on making OpenJDK more stable with 
profilers, the input he gave me on overhead and stability, and the copy editing of this document,
<a href="https://twitter.com/MGrzejszczak" target="_blank">Marcin Grzejszczak</a>
(<a href="https://www.vmware.com/pl.html" target="_blank">VMware</a>)
for great insight on how to integrate this profiler with
Spring,
<a href="https://twitter.com/k_zybala">Krystian Zybała</a> for the review.</p>

<h2 id="profiled-application">Profiled application</h2>

<p>I’ve created a Spring Boot application for this post so that you can run the following examples
on your own. It’s available on
<a href="https://github.com/krzysztofslusarski/async-profiler-demos" target="_blank">my GitHub</a>.
To build the application, do the following:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/krzysztofslusarski/async-profiler-demos
<span class="nb">cd </span>async-profiler-demos
mvn clean package
</code></pre></div></div>

<p>To run the application, you need three terminals where you run the 
following (you need the ports 8081, 8082, and 8083 available):</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="nt">-XX</span>:+AlwaysPreTouch <span class="se">\</span>
<span class="nt">-XX</span>:+UnlockDiagnosticVMOptions <span class="nt">-XX</span>:+DebugNonSafepoints <span class="se">\</span>
<span class="nt">-Duser</span>.language<span class="o">=</span>en-US <span class="se">\</span>
<span class="nt">-Xlog</span>:safepoint,gc+humongous<span class="o">=</span>trace <span class="se">\</span>
<span class="nt">-jar</span> first-application/target/first-application-0.0.1-SNAPSHOT.jar 

java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="nt">-XX</span>:+AlwaysPreTouch <span class="se">\</span>
<span class="nt">-jar</span> second-application/target/second-application-0.0.1-SNAPSHOT.jar

java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="nt">-XX</span>:+AlwaysPreTouch <span class="se">\</span>
<span class="nt">-jar</span> third-application/target/third-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>I’m using Corretto 17.0.2:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>

openjdk version <span class="s2">"17.0.2"</span> 2022-01-18 LTS
OpenJDK Runtime Environment Corretto-17.0.2.8.1 <span class="o">(</span>build 17.0.2+8-LTS<span class="o">)</span>
OpenJDK 64-Bit Server VM Corretto-17.0.2.8.1 <span class="o">(</span>build 17.0.2+8-LTS, mixed mode, sharing<span class="o">)</span>
</code></pre></div></div>

<p>And to create simple load tests, I’m using an ancient tool:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ab <span class="nt">-V</span>

This is ApacheBench, Version 2.3 &lt;<span class="nv">$Revision</span>: 1879490 <span class="nv">$&gt;</span>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/
</code></pre></div></div>

<p>I will not go through the source code to explain all the details before I jump into examples.
I often profile applications with source code I haven’t 
seen in my work. Just consider it as a typical micro-service build with Spring Boot and Hibernate.</p>

<p>In all the examples, I will assume that the application is started with the <code class="language-plaintext highlighter-rouge">java -jar</code> command.
If you are running the application from the IDE, then the name of the application is switched 
from <code class="language-plaintext highlighter-rouge">first-application-0.0.1-SNAPSHOT.jar</code> to <code class="language-plaintext highlighter-rouge">FirstApplication</code>.</p>

<p>All the JFRs generated while writing that post are available
<a href="https://github.com/krzysztofslusarski/async-profiler-demos/tree/master/jfrs" target="_blank">here</a>.</p>

<h2 id="how-to">How to run an Async-profiler</h2>

<h3 id="how-to-cl">Command line</h3>

<p>One of the easiest ways of running the async-profiler is using the command line. You just need to execute the following
in the profiler folder:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./profiler.sh <span class="nt">-e</span> &lt;event <span class="nb">type</span><span class="o">&gt;</span> <span class="nt">-d</span> &lt;duration <span class="k">in </span>seconds&gt; <span class="se">\</span>
<span class="nt">-f</span> &lt;output file name&gt; &lt;pid or application name&gt;

<span class="c"># examples</span>
./profiler.sh <span class="nt">-e</span> cpu <span class="nt">-d</span> 10 <span class="nt">-f</span> prof.jfr first-application-0.0.1-SNAPSHOT.jar
./profiler.sh <span class="nt">-e</span> wall <span class="nt">-d</span> 10 <span class="nt">-f</span> prof.html 1234 <span class="c"># where 1234 is the PID of the Java process</span>
</code></pre></div></div>

<p>There are a lot of additional switches that are explained in the <a href="https://github.com/jvm-profiling-tools/async-profiler#readme" target="_blank">README</a>.</p>

<p>You can also use async-profiler to output JFR files:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./profiler.sh start <span class="nt">-e</span> &lt;event <span class="nb">type</span><span class="o">&gt;</span> <span class="nt">-f</span> &lt;output JFR file name&gt; &lt;pid or application name&gt;
<span class="c"># do something</span>
./profiler.sh stop <span class="nt">-f</span> &lt;output JFR file name&gt; &lt;pid or application name&gt;
</code></pre></div></div>

<p>For formats different from JFR, you need to pass the file name during <code class="language-plaintext highlighter-rouge">stop</code>, but for JFR 
it is needed during <code class="language-plaintext highlighter-rouge">start</code>.</p>

<p><strong>WARNING</strong>: This way of attaching any profiler to a JVM is vulnerable to
<a href="https://bugs.openjdk.org/browse/JDK-8212155" target="_blank">JDK-8212155</a>. That issue can crash 
your JVM during attachment. It has been fixed in JDK 17.</p>

<p>If you are attaching a profiler this way, it is recommended to use <code class="language-plaintext highlighter-rouge">-XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints</code>
JVM flags (see <a href="https://jpbempel.github.io/2022/06/22/debug-non-safepoints.html" target="_blank">this blog post by Jean-Philippe Bempel</a> for more information on why these flags are essential).</p>

<h3 id="how-to-jvm">During JVM startup</h3>

<p>You can add a parameter when you are starting a <code class="language-plaintext highlighter-rouge">java</code> process:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-agentpath</span>:/path/to/libasyncProfiler.so<span class="o">=</span>start,event<span class="o">=</span>cpu,file<span class="o">=</span>prof.jfr
</code></pre></div></div>

<p>The parameters passed this way differ from the switches used in the command line approach.
You can find the list of parameters in the
<a href="https://github.com/jvm-profiling-tools/async-profiler/blob/v2.9/src/arguments.cpp#L52" target="_blank">arguments.cpp</a>
file and the mapping between those in the
<a href="https://github.com/jvm-profiling-tools/async-profiler/blob/master/profiler.sh#L149" target="_blank">profiler.sh</a> file in the
source code.</p>

<p>You can also attach a profiler without starting it using <code class="language-plaintext highlighter-rouge">-agentpath</code>, which is the safest way of starting your JVM
if you want to profile it anytime soon.</p>

<h3 id="how-to-java">From Java API</h3>

<p>The Java API is published to maven central. All you need to do is to include a dependency:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>tools.profiler<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>async-profiler<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>2.9<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>That gives you an API where you can use Async-profiler from Java code. Example usage:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">AsyncProfiler</span> <span class="n">profiler</span> <span class="o">=</span> <span class="nc">AsyncProfiler</span><span class="o">.</span><span class="na">getInstance</span><span class="o">();</span> 
</code></pre></div></div>

<p>That gives you an instance of <code class="language-plaintext highlighter-rouge">AsyncProfiler</code> object, with which you can send orders to the profiler:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">profiler</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"start,jfr,event=wall,file=%s.jfr"</span><span class="o">,</span> <span class="n">fileName</span><span class="o">));</span>
<span class="c1">// do something, like sleep</span>
<span class="n">profiler</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"stop,file=%s.jfr"</span><span class="o">,</span> <span class="n">fileName</span><span class="o">));</span>
</code></pre></div></div>

<p>Since async-profiler 2.9, the <code class="language-plaintext highlighter-rouge">AsyncProfiler.getInstance()</code> extracts and loads the <code class="language-plaintext highlighter-rouge">libasyncProfiler.so</code> from the JAR.
In the previous version, this file needed to be in one of the following directories:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">/usr/java/packages/lib</code></li>
  <li><code class="language-plaintext highlighter-rouge">/usr/lib64</code></li>
  <li><code class="language-plaintext highlighter-rouge">/lib64</code></li>
  <li><code class="language-plaintext highlighter-rouge">/lib</code></li>
  <li><code class="language-plaintext highlighter-rouge">/usr/lib</code></li>
</ul>

<p>You can also point to any location of that file with API:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">AsyncProfiler</span> <span class="n">profiler</span> <span class="o">=</span> <span class="nc">AsyncProfiler</span><span class="o">.</span><span class="na">getInstance</span><span class="o">(</span><span class="s">"/path/to/libasyncProfiler.so"</span><span class="o">);</span>
</code></pre></div></div>

<h3 id="how-to-jmh">From JMH benchmark</h3>

<p>It’s worth mentioning that the async-profiler is supported in JMH 
benchmarks. If you have one, you just need to run the following:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-jar</span> benchmarks.jar <span class="nt">-prof</span> async:libPath<span class="o">=</span>/path/to/libasyncProfiler.so<span class="se">\;</span><span class="nv">output</span><span class="o">=</span>jfr<span class="se">\;</span><span class="nv">event</span><span class="o">=</span>cpu
</code></pre></div></div>

<p>JMH will take care of every magic, and you get proper JFR files from async-profiler.</p>

<h3 id="how-to-apl">AP-Loader</h3>

<p>There is a pretty new project called <a href="https://github.com/jvm-profiling-tools/ap-loader" target="_blank">AP-Loader</a>
 by Johannes Bechberger
that can also be helpful to you. This project packages all native 
distributions into a single JAR, so
It is convenient when deploying on different CPU architectures. You can 
also use
the Java API with this loader without caring where the binary of the 
profiler is located and which platform you’re running on. I recommend 
reading
the <a href="https://github.com/jvm-profiling-tools/ap-loader#readme" target="_blank">README</a> of that project. It may be suitable for you.</p>

<h3 id="how-to-idea">IntelliJ Idea Ultimate</h3>

<p>If you are using IntelliJ Idea Ultimate, you have a built-in 
async-profiler at your fingertips. You can profile any JVM running on 
your machine and visualize the results. Honestly, I don’t use it that
much. Most of the time, I run profilers on remote machines, and I’ve got
 used to it, so I 
run it the same way on my localhost.</p>

<h2 id="out">Output formats</h2>

<p>Async-profiler gives you a choice of how the results should be saved:</p>
<ul>
  <li>default - printing results to the terminal</li>
  <li>JFR</li>
  <li>Collapsed stack</li>
  <li>Flame graphs</li>
  <li>…</li>
</ul>

<p>From that list, I choose JFR 95% of the time. It’s a binary format 
containing all the information gathered by the profiler. That file can 
be post-processed later by some external tool. I’m using my
own open-sourced <a href="https://github.com/krzysztofslusarski/jvm-profiling-toolkit" target="_blank">JVM profiling toolkit</a>,
 
which can read JFR files with additional filters and gives me the 
possibility to add/remove additional
levels during the conversion to a flame graph. I will use the filter 
names of my viewer in the following and the names of filters from my 
viewer.
There are other products (including the <code class="language-plaintext highlighter-rouge">jfr2flame</code> converter that is a part of async-profiler) 
that can visualize the JFR output, but you should use the tool that works
for you. None worked for me, so I wrote my own, but it doesn’t mean it is the best choice for everybody.</p>

<p>All flame graphs in this post are generated by my tool from JFR 
files. The JFR file format for each sample contains the following:</p>

<ul>
  <li>Stack trace</li>
  <li>Java thread name</li>
  <li>Thread state (is the Java thread consumes CPU)</li>
  <li>Timestamp</li>
  <li>Monitor class - for <code class="language-plaintext highlighter-rouge">lock</code> mode</li>
  <li>Waiting for lock duration - for <code class="language-plaintext highlighter-rouge">lock</code> mode</li>
  <li>Allocated object class - for <code class="language-plaintext highlighter-rouge">alloc</code> mode</li>
  <li>Allocated object size - for <code class="language-plaintext highlighter-rouge">alloc</code> mode</li>
  <li>Context ID - if you are using async-profiler with
<a href="https://github.com/jvm-profiling-tools/async-profiler/pull/576" target="_blank">Context ID PR</a> merged</li>
</ul>

<p>So all the information is already there. We just need to extract what we need and present it visually.</p>

<h2 id="flames">Flame graphs</h2>

<p>If you do <strong>sampling profiling</strong> you need to visualize the results. The results are nothing more than a <strong>set of stack traces</strong>.
My favorite visualization is a <strong>flame graph</strong>. The easiest way to understand what flame graphs are is to know how
they are created.</p>

<p>First, we draw a rectangle for each frame of each stack trace. The stack traces are drawn bottom-up and sorted
alphabetically. For example, such a graph looks like this:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/flame-1.png" alt="alt text" title="flame"></p>

<p>This corresponds to the following set of stack traces:</p>

<ul>
  <li>3 samples - <code class="language-plaintext highlighter-rouge">a() -&gt; h()</code></li>
  <li>5 samples - <code class="language-plaintext highlighter-rouge">b() -&gt; d() -&gt; e() -&gt; f()</code></li>
  <li>2 samples - <code class="language-plaintext highlighter-rouge">b() -&gt; d() -&gt; e() -&gt; g()</code></li>
  <li>2 samples - <code class="language-plaintext highlighter-rouge">b() -&gt; d()</code></li>
  <li>2 samples - <code class="language-plaintext highlighter-rouge">c()</code></li>
</ul>

<p>The next step is <strong>joining</strong> the rectangles with the same method name to one bar:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/flame-2.png" alt="alt text" title="flame"></p>

<p>The flame graph usually shows you how your application utilizes a specific resource. The resource is utilized
<strong>by the top methods</strong> of that graph (visualized with green bar):</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/flame-3.png" alt="flame graph with the top methods highlighted" title="flame"></p>

<p>So in this example, method <code class="language-plaintext highlighter-rouge">b()</code> does not utilize the resource. It just invokes methods that transitively use it. Flame graphs
are commonly used for the <strong>CPU utilization</strong>, but the CPU is just one of the resources we can visualize this way.
If you use <strong>wall-clock mode</strong>, your resource is <strong>time</strong>. If you use <strong>allocation mode</strong>, then your resource is
<strong>heap</strong>. If you want to learn more about flame graphs, you can check 
<a href="https://www.youtube.com/watch?v=D53T1Ejig1Q" target="_blank">Brendan’s Gregg video</a>, he invented flame graphs.</p>

<h2 id="basic-resources">Basic resources profiling</h2>

<p>Before you start any profiler, the first thing you need to know is what your goal is. Only after that
can you choose the proper mode of async-profiler. Let’s start with the basics.</p>

<h3 id="wall">Wall-clock</h3>

<p>If your goal is to optimize time, you should run the async-profiler in wall-clock mode. This is the 
most common mistake made by engineers starting their journey with profilers. The majority of
applications that I profiled so far were applications that were working with a distributed
architecture, using some DBs, MQ, Kafka, … In such applications, the majority of time is spent on
IO - waiting for other services/DB/… to respond. During such actions, Java is not using the CPU.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># warmup</span>
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 4 http://localhost:8081/examples/wall/first
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 4 http://localhost:8081/examples/wall/second

<span class="c"># profiling of the first request</span>
./profiler.sh start <span class="nt">-e</span> cpu <span class="nt">-f</span> first-cpu.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 4 http://localhost:8081/examples/wall/first
./profiler.sh stop <span class="nt">-f</span> first-cpu.jfr first-application-0.0.1-SNAPSHOT.jar

./profiler.sh start <span class="nt">-e</span> wall <span class="nt">-f</span> first-wall.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 4 http://localhost:8081/examples/wall/first
./profiler.sh stop <span class="nt">-f</span> first-wall.jfr first-application-0.0.1-SNAPSHOT.jar

<span class="c"># profiling of the second request</span>
./profiler.sh start <span class="nt">-e</span> cpu <span class="nt">-f</span> second-cpu.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 4 http://localhost:8081/examples/wall/second
./profiler.sh stop <span class="nt">-f</span> second-cpu.jfr first-application-0.0.1-SNAPSHOT.jar

./profiler.sh start <span class="nt">-e</span> wall <span class="nt">-f</span> second-wall.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 4 http://localhost:8081/examples/wall/second
./profiler.sh stop <span class="nt">-f</span> second-wall.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>In the <code class="language-plaintext highlighter-rouge">ab</code> output, we can see that the basic stats are similar for each request:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># first request</span>
Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       0
Processing:   521  654 217.9    528    1055
Waiting:      521  654 217.9    528    1054
Total:        521  654 217.9    528    1055

<span class="c"># second request</span>
Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       1
Processing:   522  665 190.2    548    1028
Waiting:      522  665 190.1    548    1028
Total:        522  665 190.2    549    1029
</code></pre></div></div>

<p>To give you a taste of how the CPU profile can mislead you, here are flame graphs for those two
executions in CPU mode.</p>

<p><strong>First execution:</strong> (<a href="https://krzysztofslusarski.github.io/assets/async-demos/wall-cpu-first.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-cpu-first.png" alt="alt text" title="flames"></p>

<p><strong>Second execution:</strong> (<a href="https://krzysztofslusarski.github.io/assets/async-demos/wall-cpu-second.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-cpu-second.png" alt="alt text" title="flames"></p>

<p>I agree that they are not identical. But they have one thing in common.
They show that the most CPU-consuming method invoked by my controller is <code class="language-plaintext highlighter-rouge">CpuConsumer.mathConsumer()</code>.
It is not a lie: It consumes CPU. But does it consume most of the time of the request? 
Look at the flame graphs in wall-clock mode:</p>

<p><strong>First execution:</strong> (<a href="https://krzysztofslusarski.github.io/assets/async-demos/wall-wall-first.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-wall-first.png" alt="alt text" title="flames"></p>

<p><strong>Second execution:</strong> (<a href="https://krzysztofslusarski.github.io/assets/async-demos/wall-wall-second.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-wall-second.png" alt="alt text" title="flames"></p>

<p>I highlighted the ```CpuConsumer.mathConsumer()`` method. Wall-clock 
mode shows us that this method is responsible just for <strong>~4%</strong> of execution time.</p>

<p><strong>Thing to remember</strong>: if your goal is to optimize time, and you use external
systems (including DBs, queues, topics, microservices) or locks, sleeps, disk IO, 
It would help if you started with wall-clock mode.</p>

<p>In wall-clock mode, we can also see that these flame graphs differ. The first 
execution spends most of its time in <code class="language-plaintext highlighter-rouge">SocketInputStream.read()</code>:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-wall-first-2.png" alt="alt text" title="flames"></p>

<p>Over <strong>95%</strong> of the time is consumed there. But the second execution:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-wall-second-2.png" alt="alt text" title="flames"></p>

<p>spends just <strong>75%</strong> on the socket. To the right of the method
<code class="language-plaintext highlighter-rouge">SocketInputStream.read()</code> you can spot an additional bar. Let’s zoom in:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-wall-second-3.png" alt="alt text" title="flames"></p>

<p>It’s the <code class="language-plaintext highlighter-rouge">InternalExecRuntime.acquireEndpoint()</code> method, which executes
<code class="language-plaintext highlighter-rouge">PoolingHttpClientConnectionManager$1.get()</code> from Apache HTTP Client, which 
in the end executes <code class="language-plaintext highlighter-rouge">Object.wait()</code>. What does it do? Basically, what we are trying
to do in those two executions is to invoke a remote REST service. The first execution
uses an HTTP Client instance with <code class="language-plaintext highlighter-rouge">20</code> available connections, so no thread
needs to wait for a connection from the pool:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// FirstApplicationConfiguration</span>
<span class="nd">@Bean</span><span class="o">(</span><span class="s">"pool20RestTemplate"</span><span class="o">)</span>
<span class="nc">RestTemplate</span> <span class="nf">pool20RestTemplate</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="nf">createRestTemplate</span><span class="o">(</span><span class="mi">20</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// WallService</span>
<span class="kt">void</span> <span class="nf">calculateAndExecuteSlow</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">Random</span> <span class="n">random</span> <span class="o">=</span> <span class="nc">ThreadLocalRandom</span><span class="o">.</span><span class="na">current</span><span class="o">();</span>
    <span class="nc">CpuConsumer</span><span class="o">.</span><span class="na">mathConsumer</span><span class="o">(</span><span class="n">random</span><span class="o">.</span><span class="na">nextDouble</span><span class="o">(),</span> <span class="no">CPU_MATH_ITERATIONS</span><span class="o">);</span>

    <span class="n">invokeWithLogTime</span><span class="o">(()</span> <span class="o">-&gt;</span>
        <span class="n">pool20RestTemplate</span><span class="o">.</span><span class="na">getForObject</span><span class="o">(</span><span class="no">SECOND_APPLICATION_URL</span> <span class="o">+</span> 
            <span class="s">"/examples/wall/slow"</span><span class="o">,</span> <span class="nc">String</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
    <span class="o">);</span>
<span class="o">}</span> 
</code></pre></div></div>

<p>The time spent on a socket is entirely spent waiting for the REST endpoint to respond.
The second execution uses a different instance of <code class="language-plaintext highlighter-rouge">RestTemplate</code> that has just 
<strong>3</strong> connections in the pool. Since the load is generated from <strong>4</strong> threads
by the <code class="language-plaintext highlighter-rouge">ab</code>, one thread must wait for a connection from the pool.
You may think this is a stupid human error, that someone created a pool without enough
connections. In the real world, the problem is with defaults that
are quite low. In our testing application, the default settings for the thread pool are:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">maxTotal</code> - <strong>25</strong> connections totally in the pool</li>
  <li><code class="language-plaintext highlighter-rouge">defaultMaxPerRoute</code> - <strong>5</strong> connections to the same address</li>
</ul>

<p>That number varies between versions. I remember one application with HTTP Client 4.x
with defaults set to <strong>2</strong>.</p>

<p>There are plenty of tools that log the invocation time of external services. The common
problem in those tools is that the time waiting on the pool for a connection is usually
included in the invocation time, which is a lie. I saw this in the past when the caller 
had a line in the logs that gave an execution time of <code class="language-plaintext highlighter-rouge">X ms</code>; the callee had a similar log
that presented <code class="language-plaintext highlighter-rouge">1/10 * X ms</code>. What were those teams doing to understand that? They
tried to convince the network department that this was a network issue. Big waste of time.</p>

<p>I also saw plenty of custom logic that traced external execution time. In our application
you can see such a pattern:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">calculateAndExecuteFast</span><span class="o">()</span> <span class="o">{</span>
    <span class="c1">// ...</span>
    <span class="n">invokeWithLogTime</span><span class="o">(()</span> <span class="o">-&gt;</span>
            <span class="n">pool3RestTemplate</span><span class="o">.</span><span class="na">getForObject</span><span class="o">(</span><span class="no">SECOND_APPLICATION_URL</span> <span class="o">+</span> <span class="s">"/examples/wall/fast"</span><span class="o">,</span> <span class="nc">String</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
    <span class="o">);</span>
<span class="o">}</span>

<span class="kd">private</span> <span class="o">&lt;</span><span class="no">T</span><span class="o">&gt;</span> <span class="no">T</span> <span class="nf">invokeWithLogTime</span><span class="o">(</span><span class="nc">Supplier</span><span class="o">&lt;</span><span class="no">T</span><span class="o">&gt;</span> <span class="n">toInvoke</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">StopWatch</span> <span class="n">stopWatch</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">StopWatch</span><span class="o">();</span>

    <span class="n">stopWatch</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
    <span class="no">T</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">toInvoke</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
    <span class="n">stopWatch</span><span class="o">.</span><span class="na">stop</span><span class="o">();</span>

    <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"External WS invoked in: {}ms"</span><span class="o">,</span> <span class="n">stopWatch</span><span class="o">.</span><span class="na">getTotalTimeMillis</span><span class="o">());</span>
    <span class="k">return</span> <span class="n">ret</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>The logs don’t trace the time using an external service; the time also includes all the magic done by
Spring, including waiting for a connection from the pool. You can easily see that for the second request,
the logs look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>External WS invoked in: 937ms
</code></pre></div></div>

<p>But the second service that is invoked is:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="nd">@GetMapping</span><span class="o">(</span><span class="s">"/fast"</span><span class="o">)</span>
    <span class="nc">String</span> <span class="nf">fast</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">InterruptedException</span> <span class="o">{</span>
        <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">500</span><span class="o">);</span>
        <span class="k">return</span> <span class="s">"OK"</span><span class="o">;</span>
    <span class="o">}</span>
</code></pre></div></div>

<h3 id="wall-filter">Wall-clock - filtering</h3>

<p>If you open the wall-clock flame graph for the first time, you may be confused, since
it usually looks like this:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/wall-filter.png" alt="alt text" title="flames"></p>

<p>You see all the threads, even if they are sleeping or waiting in some queue for a job.
Wall-clock shows you all of them.  Most of the time, you want to focus on the frames where
your application is doing something, not when it is waiting. 
All you need to do is to filter the stack traces. If you are using Spring Boot 
with the embedded Tomcat, you can filter
stack traces that contain the <code class="language-plaintext highlighter-rouge">SocketProcessorBase.run</code> method. 
In my viewer, you can just paste it to <em>stack trace filter</em>, and you are done. 
It’s just a matter of proper filtering if you want to focus on one controller, class, method, etc.</p>

<h3 id="cpu-easy">CPU - easy-peasy</h3>

<p>If you know that your application is CPU intensive, or you want to decrease CPU consumption, 
then the CPU mode is suitable.</p>

<p>Let’s prepare our application:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># execute it once</span>
curl <span class="nt">-v</span> http://localhost:8081/examples/cpu/prepare

<span class="c"># little warmup</span>
ab <span class="nt">-n</span> 5 <span class="nt">-c</span> 1 http://localhost:8081/examples/cpu/inverse

<span class="c"># profiling time:</span>
./profiler.sh start <span class="nt">-e</span> cpu <span class="nt">-f</span> cpu.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 5 <span class="nt">-c</span> 1 http://localhost:8081/examples/cpu/inverse
./profiler.sh stop <span class="nt">-f</span> cpu.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>You can check during the benchmark what the CPU utilization of our JVM is:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>pidstat <span class="nt">-p</span> <span class="sb">`</span>pgrep <span class="nt">-f</span> first-application-0.0.1-SNAPSHOT.jar<span class="sb">`</span> 5
 
09:42:49      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
09:42:54     1000     49813  115,40    0,40    0,00    0,00  115,80     1  java
09:42:59     1000     49813  111,40    0,60    0,00    0,00  112,00     1  java
09:43:04     1000     49813  106,80    0,20    0,00    0,00  107,00     1  java
09:43:09     1000     49813  113,00    0,20    0,00    0,00  113,20     1  java 
</code></pre></div></div>

<p>We are using a bit more than one CPU core. Our load generator creates the load with a single
thread so that the CPU usage is pretty high. Let’s see what our CPU is doing while executing our
spring controller: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/cpu.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cpu.png" alt="alt text" title="flames"></p>

<p>I know that flame graph is pretty large, but hey, welcome to Spring and Hibernate.
I highlighted the <code class="language-plaintext highlighter-rouge">existsById()</code> method. You can see that it consumes <strong>95%</strong> of the
CPU time. But why? It doesn’t look scary at all when looking at the code:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Transactional</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">inverse</span><span class="o">(</span><span class="no">UUID</span> <span class="n">uuid</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">sampleEntityRepository</span><span class="o">.</span><span class="na">findById</span><span class="o">(</span><span class="n">uuid</span><span class="o">).</span><span class="na">ifPresent</span><span class="o">(</span><span class="n">sampleEntity</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="kt">boolean</span> <span class="n">allConfigPresent</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="n">allConfigPresent</span> <span class="o">=</span> <span class="n">allConfigPresent</span> <span class="o">&amp;&amp;</span> <span class="n">sampleConfigurationRepository</span><span class="o">.</span><span class="na">existsById</span><span class="o">(</span><span class="s">"key-"</span> <span class="o">+</span> <span class="n">i</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="n">sampleEntity</span><span class="o">.</span><span class="na">setFlag</span><span class="o">(!</span><span class="n">sampleEntity</span><span class="o">.</span><span class="na">isFlag</span><span class="o">());</span>
    <span class="o">});</span>
<span class="o">}</span>
</code></pre></div></div>

<p>We are just executing <code class="language-plaintext highlighter-rouge">existsById()</code> on the Spring Data JPA repository. The answer 
why that method is slow is at the beginning of the method:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sampleEntityRepository</span><span class="o">.</span><span class="na">findById</span><span class="o">(</span><span class="n">uuid</span><span class="o">)</span>
</code></pre></div></div>

<p>and in JPA mapping:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SampleEntity</span> <span class="o">{</span>
    <span class="nd">@Id</span>
    <span class="kd">private</span> <span class="no">UUID</span> <span class="n">id</span><span class="o">;</span>

    <span class="nd">@Fetch</span><span class="o">(</span><span class="nc">FetchMode</span><span class="o">.</span><span class="na">JOIN</span><span class="o">)</span>
    <span class="nd">@JoinColumn</span><span class="o">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">"fk_entity"</span><span class="o">)</span>
    <span class="nd">@OneToMany</span><span class="o">(</span><span class="n">cascade</span> <span class="o">=</span> <span class="nc">CascadeType</span><span class="o">.</span><span class="na">ALL</span><span class="o">,</span> <span class="n">fetch</span> <span class="o">=</span> <span class="nc">FetchType</span><span class="o">.</span><span class="na">EAGER</span><span class="o">,</span> <span class="n">orphanRemoval</span> <span class="o">=</span> <span class="kc">true</span><span class="o">)</span>
    <span class="kd">private</span> <span class="nc">Set</span><span class="o">&lt;</span><span class="nc">SampleSubEntity</span><span class="o">&gt;</span> <span class="n">subEntities</span><span class="o">;</span>

    <span class="kd">private</span> <span class="kt">boolean</span> <span class="n">flag</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>This means that when we get one <code class="language-plaintext highlighter-rouge">SampleEntity</code> by id, we also extract the <code class="language-plaintext highlighter-rouge">subEntities</code> from the database because of <code class="language-plaintext highlighter-rouge">fetch = FetchType.EAGER</code>.
This is not a problem yet. All JPA entities are loaded into the Hibernate session.
That mechanism is pretty cool because it gives you the <em>dirty checking</em> functionality.
The downside, however, is that the <em>dirty</em> entities need to be flushed by Hibernate 
to DB. You have different flush strategies in Hibernate. The default one is <code class="language-plaintext highlighter-rouge">AUTO</code>:
you can read about them in the
<a href="https://javadoc.io/doc/org.hibernate/hibernate-core/5.6.14.Final/org/hibernate/FlushMode.html" target="_blank">Javadocs</a>.
What you see in the flame graph is exactly Hibernate looking for dirty entities that
should be flushed.</p>

<p>What can we do about this? Well, first of all, it should be forbidden to develop
a large Hibernate application without reading 
<a href="https://vladmihalcea.com/books/high-performance-java-persistence/" target="_blank">Vlad Mihalcea’s book</a>.
If you are developing such an application, buy that book, it’s great. From my experience, 
some engineers tend to abuse Hibernate. Let’s look at the code sample I pasted 
before. We are loading a huge <code class="language-plaintext highlighter-rouge">SampleEntity</code>. What are we doing with it?</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Transactional</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">inverse</span><span class="o">(</span><span class="no">UUID</span> <span class="n">uuid</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">sampleEntityRepository</span><span class="o">.</span><span class="na">findById</span><span class="o">(</span><span class="n">uuid</span><span class="o">).</span><span class="na">ifPresent</span><span class="o">(</span><span class="n">sampleEntity</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// irrelevant</span>
        <span class="n">sampleEntity</span><span class="o">.</span><span class="na">setFlag</span><span class="o">(!</span><span class="n">sampleEntity</span><span class="o">.</span><span class="na">isFlag</span><span class="o">());</span>
    <span class="o">});</span>
<span class="o">}</span>
</code></pre></div></div>

<p>So we’re basically changing one column in one row in the DB. We can do it more efficiently 
by using the <code class="language-plaintext highlighter-rouge">update</code> query, even with Spring Data JPA repository or simple JDBC.
But do we really need to use Hibernate everywhere?</p>

<h3 id="cpu-hard">CPU - a bit harder</h3>

<p>Sometimes the result of a CPU profiler is just the beginning of the fun. Let’s consider the following example:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># little warmup</span>
ab <span class="nt">-n</span> 10 <span class="nt">-c</span> 1 http://localhost:8081/examples/cpu/matrix-slow

<span class="c"># profiling time</span>
./profiler.sh start <span class="nt">-e</span> cpu <span class="nt">-f</span> matrix-slow.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 10 <span class="nt">-c</span> 1 http://localhost:8081/examples/cpu/matrix-slow
./profiler.sh stop <span class="nt">-f</span> matrix-slow.jfr first-application-0.0.1-SNAPSHOT.jar

<span class="c"># little warmup</span>
ab <span class="nt">-n</span> 10 <span class="nt">-c</span> 1 http://localhost:8081/examples/cpu/matrix-fast

<span class="c"># profiling time</span>
./profiler.sh start <span class="nt">-e</span> cpu <span class="nt">-f</span> matrix-fast.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 10 <span class="nt">-c</span> 1 http://localhost:8081/examples/cpu/matrix-fast
./profiler.sh stop <span class="nt">-f</span> matrix-fast.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>Let’s see the run times of the <code class="language-plaintext highlighter-rouge">matrix-slow</code> request:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:  1601 1795 181.5   1785    2078
Waiting:     1600 1794 181.5   1785    2077
Total:       1601 1795 181.5   1786    2078
</code></pre></div></div>

<p>The profile looks like the following: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/cpu-hard-slow.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cpu-hard-slow.png" alt="alt text" title="flames"></p>

<p>The whole CPU is wasted in the <code class="language-plaintext highlighter-rouge">matrixMultiplySlow</code> method:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">static</span> <span class="kt">int</span><span class="o">[][]</span> <span class="nf">matrixMultiplySlow</span><span class="o">(</span><span class="kt">int</span><span class="o">[][]</span> <span class="n">a</span><span class="o">,</span> <span class="kt">int</span><span class="o">[][]</span> <span class="n">b</span><span class="o">,</span> <span class="kt">int</span> <span class="n">size</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span><span class="o">[][]</span> <span class="n">result</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[</span><span class="n">size</span><span class="o">][</span><span class="n">size</span><span class="o">];</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">size</span><span class="o">;</span> <span class="n">j</span><span class="o">++)</span> <span class="o">{</span>
            <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
            <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">size</span><span class="o">;</span> <span class="n">k</span><span class="o">++)</span> <span class="o">{</span>
                <span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span><span class="o">]</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
            <span class="o">}</span>
            <span class="n">result</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">j</span><span class="o">]</span> <span class="o">=</span> <span class="n">sum</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="k">return</span> <span class="n">result</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>If we look at the run times of the <code class="language-plaintext highlighter-rouge">matrix-fast</code> request:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:   107  114   6.5    114     128
Waiting:      106  113   6.5    113     128
Total:        107  114   6.5    114     128
</code></pre></div></div>

<p>That request is <strong>18 times faster</strong> than the <code class="language-plaintext highlighter-rouge">matrix-slow</code> request, but if we look at the profile
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/cpu-hard-fast.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cpu-hard-fast.png" alt="alt text" title="flames"></p>

<p>We see that the whole CPU is wasted in the method <code class="language-plaintext highlighter-rouge">matrixMultiplyFaster</code>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">static</span> <span class="kt">int</span><span class="o">[][]</span> <span class="nf">matrixMultiplyFaster</span><span class="o">(</span><span class="kt">int</span><span class="o">[][]</span> <span class="n">a</span><span class="o">,</span> <span class="kt">int</span><span class="o">[][]</span> <span class="n">b</span><span class="o">,</span> <span class="kt">int</span> <span class="n">size</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span><span class="o">[][]</span> <span class="n">result</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[</span><span class="n">size</span><span class="o">][</span><span class="n">size</span><span class="o">];</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">size</span><span class="o">;</span> <span class="n">k</span><span class="o">++)</span> <span class="o">{</span>
            <span class="kt">int</span> <span class="n">current</span> <span class="o">=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span><span class="o">];</span>
            <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">size</span><span class="o">;</span> <span class="n">j</span><span class="o">++)</span> <span class="o">{</span>
                <span class="n">result</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">j</span><span class="o">]</span> <span class="o">+=</span> <span class="n">current</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="k">return</span> <span class="n">result</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>
<p>Both methods <code class="language-plaintext highlighter-rouge">matrixMultiplySlow</code> and <code class="language-plaintext highlighter-rouge">matrixMultiplyFaster</code> have the same complexity O(n^3). So
why is one faster than the other? Well, if you want to understand exactly how a CPU-intensive algorithm works, 
you need to understand how the CPU works, which is far away from the topic of this post. Be aware that if
you want to optimize such algorithms; you will probably need at least one of the following:</p>

<ul>
  <li>Knowledge of CPU architecture</li>
  <li>Top-Down performance analysis methodology</li>
  <li>Looking at the ASM of generated methods</li>
</ul>

<p>Many Java programmers forget that all the execution is done on the CPU. Java needs to use ASM to run on the CPU. That’s
basically what the JIT compiler does: It converts your hot methods and loops into optimized ASM. At the assembly level,
you can check, for example, if the JIT used vectorized instruction for your loops. So yes, sometimes you need to get dirty 
with such low-level stuff. For now, async-profiler gives you a hint on which methods to focus.</p>

<p>We will return to this example in the <a href="#perf-cache">Cache misses</a> section.</p>

<h3 id="alloc">Allocation</h3>

<p>The most common use cases where the allocations are tracked are:</p>

<ul>
  <li>decreasing GC run frequency</li>
  <li>finding allocations outside the TLAB, which are done in the slow path</li>
  <li>fighting with single/tens of milliseconds latency, where even the creation of heap objects matters</li>
</ul>

<p>First, let’s understand how new objects on a heap are created so we have a better
understanding of what the async-profiler shows us.</p>

<p>A portion of our Java heap is called an <strong>eden</strong>. This is a place where new objects are
born. Let’s assume for simplicity that eden is a continuous slice of memory. The very efficient
way of allocation in such a case is called <strong>bumping pointer</strong>. We keep a pointer to the first 
address of the free space:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/alloc-1.png" alt="alt text" title="alloc"></p>

<p>When we do <code class="language-plaintext highlighter-rouge">new Object()</code>, we simply calculate its size, locate 
the next free address and bump the pointer by <code class="language-plaintext highlighter-rouge">sizeof(Object)</code>:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/alloc-2.png" alt="alt text" title="alloc"></p>

<p>But there is one major problem with that technique: We have to 
synchronize the object allocation if we have more than one thread that 
can 
create new objects in parallel, but this is quite costly. We solve this 
by giving each thread a portion of eden dedicated to only that thread. 
This portion 
is called <strong>TLAB</strong> - thread-local allocation buffer. With this, each thread can use <strong>bumping pointer</strong> at its TLAB safely and in parallel.</p>

<p>Introducing TLABs creates two more issues that the JVM needs to deal with:</p>

<ul>
  <li>a thread can allocate an object, but there is not enough space in 
its TLAB - the JVM creates a new TLAB if there is still space in eden</li>
  <li>a thread can allocate a big object, so it’s not optimal to use the TLAB mechanism - the JVM will use the <em>slow path</em> of the allocation that allocates the object directly in eden or in the old generation</li>
</ul>

<p>What is important to us is that in both these cases, the JVM emits an
 event that a profiler can capture. That’s basically how async-profiler 
samples allocations:</p>

<ul>
  <li>if the allocation of an object needed a new TLAB - we see an aqua frame for that</li>
  <li>if the allocation was done outside the TLAB - we see a brown frame</li>
</ul>

<p>In real-world systems, the frequency of GC can be monitored by systems like Grafana or Zabbix.
Here we have a synthetic application, so let’s measure the allocation size differently:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># little warmup</span>
ab <span class="nt">-n</span> 2 <span class="nt">-c</span> 1 http://localhost:8081/examples/alloc/

<span class="c"># measuring the heap allocations of a request</span>
jcmd first-application-0.0.1-SNAPSHOT.jar GC.run
jcmd first-application-0.0.1-SNAPSHOT.jar GC.heap_info
ab <span class="nt">-n</span> 10 <span class="nt">-c</span> 1 http://localhost:8081/examples/alloc/
jcmd first-application-0.0.1-SNAPSHOT.jar GC.heap_info

<span class="c"># profiling time</span>
./profiler.sh start <span class="nt">-e</span> alloc <span class="nt">-f</span> alloc.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000 <span class="nt">-c</span> 1 http://localhost:8081/examples/alloc/
./profiler.sh stop <span class="nt">-f</span> alloc.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>Let’s look at the output of the <code class="language-plaintext highlighter-rouge">GC.heap_info</code> command:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code> garbage-first heap   total 1048576K, used 41926K <span class="o">[</span>0x00000000c0000000, 0x0000000100000000<span class="o">)</span>
  region size 1024K, 2 young <span class="o">(</span>2048K<span class="o">)</span>, 0 survivors <span class="o">(</span>0K<span class="o">)</span>
 Metaspace       used 67317K, committed 67904K, reserved 1114112K
  class space    used 9868K, committed 10176K, reserved 1048576K

 garbage-first heap   total 1048576K, used 110018K <span class="o">[</span>0x00000000c0000000, 0x0000000100000000<span class="o">)</span>
  region size 1024K, 8 young <span class="o">(</span>8192K<span class="o">)</span>, 0 survivors <span class="o">(</span>0K<span class="o">)</span>
 Metaspace       used 67317K, committed 67904K, reserved 1114112K
  class space    used 9868K, committed 10176K, reserved 1048576K
</code></pre></div></div>

<p>We executed <code class="language-plaintext highlighter-rouge">alloc</code> requests ten times, and our heap usage has increased from <strong>41926K</strong> to <strong>110018K</strong>.
So we are creating over <strong>6MB</strong> of objects per request on the heap. If we look at the controller source code
it’s hard to justify that:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@RestController</span>
<span class="nd">@RequestMapping</span><span class="o">(</span><span class="s">"/examples/alloc"</span><span class="o">)</span>
<span class="nd">@RequiredArgsConstructor</span>
<span class="kd">class</span> <span class="nc">AllocController</span> <span class="o">{</span>
    <span class="nd">@GetMapping</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span>
    <span class="nc">String</span> <span class="nf">get</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="s">"OK"</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Let’s look at the allocation flame graph: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/alloc.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/alloc.png" alt="alt text" title="flames"></p>

<p>The class <code class="language-plaintext highlighter-rouge">AbstractRequestLoggingFilter</code> is responsible for over <strong>99%</strong> of recorder allocations. 
You can find its main creation sites using the techniques from the <a href="#methods">Methods profiling</a> section; feel free to skip it for now.
Here is the answer:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="nc">CommonsRequestLoggingFilter</span> <span class="nf">requestLoggingFilter</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">CommonsRequestLoggingFilter</span> <span class="n">loggingFilter</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CommonsRequestLoggingFilter</span><span class="o">()</span> <span class="o">{</span>
        <span class="nd">@Override</span>
        <span class="kd">protected</span> <span class="kt">boolean</span> <span class="nf">shouldNotFilter</span><span class="o">(</span><span class="nc">HttpServletRequest</span> <span class="n">request</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">ServletException</span> <span class="o">{</span>
            <span class="k">return</span> <span class="o">!</span><span class="n">request</span><span class="o">.</span><span class="na">getRequestURI</span><span class="o">().</span><span class="na">contains</span><span class="o">(</span><span class="s">"alloc"</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">};</span>

    <span class="n">loggingFilter</span><span class="o">.</span><span class="na">setIncludeClientInfo</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
    <span class="n">loggingFilter</span><span class="o">.</span><span class="na">setIncludeQueryString</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
    <span class="n">loggingFilter</span><span class="o">.</span><span class="na">setIncludePayload</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
    <span class="n">loggingFilter</span><span class="o">.</span><span class="na">setMaxPayloadLength</span><span class="o">(</span><span class="mi">5</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">);</span>
    <span class="n">loggingFilter</span><span class="o">.</span><span class="na">setIncludeHeaders</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
    <span class="k">return</span> <span class="n">loggingFilter</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>I have seen such code many times; this <code class="language-plaintext highlighter-rouge">CommonsRequestLoggingFilter</code>class helps you log
the REST endpoint communication. The <code class="language-plaintext highlighter-rouge">setMaxPayloadLength()</code> method sets the maximum number of bytes of the payload which are logged. 
You can browse over the Spring source code to see that the implementation creates byte arrays of
such size in the constructor. No matter how big the payload is, we always create a <strong>5MB</strong> array here.</p>

<p>The advice that I gave to users of that code was to create their own filter that would do the same job
but allocate the array lazily.</p>

<h3 id="alloc-ha">Allocation - humongous objects</h3>

<p>If you use the G1 garbage collector, JVM’s default since JDK 9, your heap is divided into
regions. The region sizes vary from <strong>1 MB</strong> to <strong>32 MB</strong> depending on the heap size. The goal is to have no more than <strong>2048</strong> regions.
You can check the region size for different heap sizes with the following:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="nt">-Xlog</span>:gc,exit<span class="k">*</span><span class="o">=</span>debug <span class="nt">-version</span>
</code></pre></div></div>

<p>The output contains a line containing the <code class="language-plaintext highlighter-rouge">region size 1024K</code> information.</p>

<p>If you are trying to allocate an object larger or equal to half of 
the region size, 
you are doing a humongous allocation. Long story short: It has been, and
 it is, painful. 
It is allocated directly in the old generation but is cleared during 
minor GCs. I saw situations
where G1 GC needed to invoke a FullGC phase because of the humongous 
allocation. If you do much of this, G1 will also invoke more concurrent 
collections, which can waste your CPU.</p>

<p>While running the previous example, you could spot in <code class="language-plaintext highlighter-rouge">first-application-0.0.1-SNAPSHOT.jar</code> logs:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
<span class="o">[</span>70,149s][debug][gc,humongous] GC<span class="o">(</span>34<span class="o">)</span> Reclaimed humongous region 436 <span class="o">(</span>object size 5242896 @ 0x00000000db400000<span class="o">)</span>
<span class="o">[</span>70,149s][debug][gc,humongous] GC<span class="o">(</span>34<span class="o">)</span> Reclaimed humongous region 442 <span class="o">(</span>object size 5242896 @ 0x00000000dba00000<span class="o">)</span>
<span class="o">[</span>70,149s][debug][gc,humongous] GC<span class="o">(</span>34<span class="o">)</span> Reclaimed humongous region 448 <span class="o">(</span>object size 5242896 @ 0x00000000dc000000<span class="o">)</span>
<span class="o">[</span>70,149s][debug][gc,humongous] GC<span class="o">(</span>34<span class="o">)</span> Reclaimed humongous region 454 <span class="o">(</span>object size 5242896 @ 0x00000000dc600000<span class="o">)</span>
...
</code></pre></div></div>

<p>These GC logs tell us that some humongous object of size <code class="language-plaintext highlighter-rouge">5242896</code> was reclaimed. The nice thing
about JFR files is that they also keep the size of sampled allocations. Using this, we should be able to find out
the stack trace that has created that object.</p>

<p>We don’t need sophisticated JFR viewers for that. We get the <code class="language-plaintext highlighter-rouge">jfr</code> command with any JDK distribution. Let’s use it:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>jfr summary alloc.jfr
...
 Event Type                          Count  Size <span class="o">(</span>bytes<span class="o">)</span> 
<span class="o">=========================================================</span>
 jdk.ObjectAllocationOutsideTLAB      1013         19220
 jdk.ObjectAllocationInNewTLAB         359          6719
...
</code></pre></div></div>

<p>Let’s focus on allocations outside the TLAB; it is unlikely to allocate humongous objects in the TLAB.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>jfr print <span class="nt">--events</span> jdk.ObjectAllocationOutsideTLAB <span class="nt">--stack-depth</span> 10 alloc.jfr
...
jdk.ObjectAllocationOutsideTLAB <span class="o">{</span>
  startTime <span class="o">=</span> 2022-12-05T08:56:04.354766183Z
  objectClass <span class="o">=</span> byte[] <span class="o">(</span>classLoader <span class="o">=</span> null<span class="o">)</span>
  allocationSize <span class="o">=</span> 5242896
  eventThread <span class="o">=</span> <span class="s2">"http-nio-8081-exec-9"</span> <span class="o">(</span>javaThreadId <span class="o">=</span> 49<span class="o">)</span>
  stackTrace <span class="o">=</span> <span class="o">[</span>
    java.io.ByteArrayOutputStream.&lt;init&gt;<span class="o">(</span>int<span class="o">)</span> line: 81
    org.springframework.web.util.ContentCachingRequestWrapper.&lt;init&gt;<span class="o">(</span>HttpServletRequest, int<span class="o">)</span> line: 90
    org.springframework.web.filter.AbstractRequestLoggingFilter.doFilterInternal<span class="o">(</span>HttpServletRequest, HttpServletResponse, FilterChain<span class="o">)</span> line: 281
    org.springframework.web.filter.OncePerRequestFilter.doFilter<span class="o">(</span>ServletRequest, ServletResponse, FilterChain<span class="o">)</span> line: 116
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter<span class="o">(</span>ServletRequest, ServletResponse<span class="o">)</span> line: 185
    org.apache.catalina.core.ApplicationFilterChain.doFilter<span class="o">(</span>ServletRequest, ServletResponse<span class="o">)</span> line: 158
    org.springframework.web.filter.RequestContextFilter.doFilterInternal<span class="o">(</span>HttpServletRequest, HttpServletResponse, FilterChain<span class="o">)</span> line: 100
    org.springframework.web.filter.OncePerRequestFilter.doFilter<span class="o">(</span>ServletRequest, ServletResponse, FilterChain<span class="o">)</span> line: 116
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter<span class="o">(</span>ServletRequest, ServletResponse<span class="o">)</span> line: 185
    org.apache.catalina.core.ApplicationFilterChain.doFilter<span class="o">(</span>ServletRequest, ServletResponse<span class="o">)</span> line: 158
    ...
  <span class="o">]</span>
<span class="o">}</span>
...
</code></pre></div></div>

<p>We can easily match <code class="language-plaintext highlighter-rouge">allocationSize = 5242896</code>`
 with the object size from the GC logs, so we can find and eliminate 
humongous allocations using that technique. You can filter the 
allocation
JFR file for objects with a size larger or equal to half of our G1 
region size. All of 
these allocations are humongous allocations.</p>

<h3 id="alloc-live">Allocation - live objects</h3>

<p>Now on to memory leaks, which form the reason for tracking live object allocations:</p>

<blockquote>
  <p>A memory leak occurs when a <em>Garbage Collector</em> cannot collect Objects that are no longer needed by the Java application.</p>
</blockquote>

<p>Memory leaks are one of the most common problems related to Java heaps; the other is</p>

<ul>
  <li><strong>not enough space on a heap</strong> - sometimes, a Java 
application may work fine with the heap it has, but there is the 
possibility to run a part of the application
that needs more heap than specified via <strong>-Xmx</strong></li>
  <li><strong>a gray area between</strong> - these are cases when we allocate memory indefinitely, but our application needs these objects</li>
</ul>

<p>How can we detect memory leaks? The GC emits the following kind of entry at the end of each <em>GC cycle</em> into the GC logs at <em>info</em> level:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GC(11536) Pause Young (Normal) (G1 Evacuation Pause) 6746M-&gt;2016M(8192M) 40.514ms
</code></pre></div></div>

<p>You can find <strong>three</strong> sizes in such an entry <strong>A-&gt;B(C)</strong> that are:</p>
<ul>
  <li><strong>A</strong> - used size of a heap before <em>GC cycle</em></li>
  <li><strong>B</strong> - used size of a heap after <em>GC cycle</em></li>
  <li><strong>C</strong> - the current size of a whole heap</li>
</ul>

<p>If we take the <strong>B</strong> value from each collection and put it on a chart, we can generate the 
<em>Heap after GC</em> chart. We can use such a chart to then detect if we have a memory leak:
If a chart looks like those (from a <strong>7 days</strong> period):</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/1.jpg" alt="alt text" title="1"></p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/4.jpg" alt="alt text" title="4"></p>

<p>then there is <strong>no memory leak</strong>. The <em>garbage collector</em> can clean up the heap to 
the same level every day. The chart with a memory leak looks like the following one:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/2.jpg" alt="alt text" title="2"></p>

<p>These spikes to the roof are <em>to-space exhausted</em> situations in the <strong>G1</strong> algorithm; those are not <em>OutOfMemoryErrors</em>. After each of those spikes, there was a
<strong>Full GC</strong> phase that is a <strong>failover</strong> in that algorithm.</p>

<p>Here is an example of the <strong>not enough space on a heap</strong> problem:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/3.jpg" alt="alt text" title="3"></p>

<p>This one spike is an <em>OutOfMemoryError</em>. One service was run with arguments that needed <strong>~16GB</strong> on a heap to complete. 
Unfortunately <strong>-Xmx</strong> was set to
<strong>4GB</strong>. <strong>It is not a memory leak</strong>.</p>

<p>We must be careful if our application is entirely stateless and we use GC with <strong>young/old generations</strong> (like G1, parallel, serial, and CMS).
We must remember that objects from a <strong>memory leak</strong> live in the <strong>old generation</strong>. 
In stateless applications, that part of the heap can be cleared even once a
week. Here is an example recording <strong>3 days</strong> of the stateless application:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/5.jpg" alt="alt text" title="5"></p>

<p>It looks like a memory leak, the <code class="language-plaintext highlighter-rouge">min(heap after GC)</code> increasing every day, but if we look at the same chart with one additional day:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/6.jpg" alt="alt text" title="6"></p>

<p>The GC cleared the heap to the previous level. This was done by an <strong>old-generation</strong> cleanup that didn’t happen in the previous days.</p>

<p>The <em>Heap after GC</em> chart can be generated by probing through JMX. The JVM gives that information via mBeans:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">java.lang:type=GarbageCollector,name=G1 Young Generation</code></li>
  <li><code class="language-plaintext highlighter-rouge">java.lang:type=GarbageCollector,name=G1 Old Generation</code></li>
</ul>

<p>Both mBeans provide attributes with the name <code class="language-plaintext highlighter-rouge">LastGcInfo</code> from which we can extract the needed information.</p>

<p>Most memory leaks I discovered in recent years in enterprise applications were either in
frameworks/libraries or in some kind of bridge between them. Recreating such an issue in our example
application would require introducing a lot of strange dependencies, so I chose to
recreate one custom-made heap memory leak I discovered a few years ago.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># preparation</span>
curl http://localhost:8081/examples/leak/prepare
ab <span class="nt">-n</span> 1000 <span class="nt">-c</span> 4 http://localhost:8081/examples/leak/do-leak

<span class="c"># profiling</span>
jcmd first-application-0.0.1-SNAPSHOT.jar GC.run 
jcmd first-application-0.0.1-SNAPSHOT.jar GC.heap_info
./profiler.sh start <span class="nt">-e</span> alloc <span class="nt">--live</span> <span class="nt">-f</span> live.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000000 <span class="nt">-c</span> 4 http://localhost:8081/examples/leak/do-leak
jcmd first-application-0.0.1-SNAPSHOT.jar GC.run
jcmd first-application-0.0.1-SNAPSHOT.jar GC.heap_info
./profiler.sh stop <span class="nt">-f</span> live.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>Let’s look at the output of the <code class="language-plaintext highlighter-rouge">GC.heap_info</code> commands that were invoked soon after running the GC:</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code> garbage-first heap   total 1048576K, used 50144K <span class="o">[</span>0x00000000c0000000, 0x0000000100000000<span class="o">)</span>
  region size 1024K, 1 young <span class="o">(</span>1024K<span class="o">)</span>, 0 survivors <span class="o">(</span>0K<span class="o">)</span>
 Metaspace       used 68750K, committed 69376K, reserved 1114112K
  class space    used 10054K, committed 10368K, reserved 1048576K

 garbage-first heap   total 1048576K, used 237806K <span class="o">[</span>0x00000000c0000000, 0x0000000100000000<span class="o">)</span>
  region size 1024K, 1 young <span class="o">(</span>1024K<span class="o">)</span>, 0 survivors <span class="o">(</span>0K<span class="o">)</span>
 Metaspace       used 68841K, committed 69440K, reserved 1114112K
  class space    used 10063K, committed 10368K, reserved 1048576K
</code></pre></div></div>

<p>So invoking our <code class="language-plaintext highlighter-rouge">do-leak</code> request created <strong>~183MB</strong> of objects that GC couldn’t free.</p>

<p>Let’s look at the allocation flame graph with the <code class="language-plaintext highlighter-rouge">--live</code> option enabled: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/live.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/live.png" alt="alt text" title="flames"></p>

<p>The largest part of the leak is created in the <code class="language-plaintext highlighter-rouge">JdbcQueryProfiler</code> class; let’s look at the sources:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">JdbcQueryProfiler</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">ProfilingData</span><span class="o">&gt;</span> <span class="n">profilingResults</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ConcurrentHashMap</span><span class="o">&lt;&gt;();</span>
  
    <span class="o">&lt;</span><span class="no">T</span><span class="o">&gt;</span> <span class="no">T</span> <span class="nf">runWithProfiler</span><span class="o">(</span><span class="nc">String</span> <span class="n">queryStr</span><span class="o">,</span> <span class="nc">Supplier</span><span class="o">&lt;</span><span class="no">T</span><span class="o">&gt;</span> <span class="n">query</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">StopWatch</span> <span class="n">stopWatch</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">StopWatch</span><span class="o">();</span>
        <span class="n">stopWatch</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
        <span class="no">T</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
        <span class="n">stopWatch</span><span class="o">.</span><span class="na">stop</span><span class="o">();</span>
        <span class="n">profilingResults</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">queryStr</span><span class="o">,</span> <span class="nl">ProfilingData:</span><span class="o">:</span><span class="k">new</span><span class="o">).</span><span class="na">nextInvocation</span><span class="o">(</span><span class="n">stopWatch</span><span class="o">.</span><span class="na">getTotalTimeMillis</span><span class="o">());</span>
        <span class="k">return</span> <span class="n">ret</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="c1">// ...</span>
<span class="o">}</span>
</code></pre></div></div>

<p>So that class calculates the execution time for each query and remembers it in
some <code class="language-plaintext highlighter-rouge">ProfilingData</code> structure that is placed in <code class="language-plaintext highlighter-rouge">ConcurrentHashMap</code>. That doesn’t look scary; as long as we use parametrized queries under our control, the map should have a finite size.
Let’s look at the usage of the <code class="language-plaintext highlighter-rouge">runWithProfiler()</code> method:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">String</span> <span class="nf">getValueForKey</span><span class="o">(</span><span class="kt">int</span> <span class="n">key</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">String</span> <span class="n">sql</span> <span class="o">=</span> <span class="s">"select a_value from LEAKY_ENTITY where a_Key = "</span> <span class="o">+</span> <span class="n">key</span><span class="o">;</span>

    <span class="k">return</span> <span class="n">jdbcQueryProfiler</span><span class="o">.</span><span class="na">runWithProfiler</span><span class="o">(</span><span class="n">sql</span><span class="o">,</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="k">try</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">jdbcTemplate</span><span class="o">.</span><span class="na">queryForObject</span><span class="o">(</span><span class="n">sql</span><span class="o">,</span> <span class="nc">String</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">EmptyResultDataAccessException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">return</span> <span class="kc">null</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">});</span>
<span class="o">}</span>
</code></pre></div></div>

<p>So, well, so good; we are not using parameterized queries; we create new query strings for every <code class="language-plaintext highlighter-rouge">key</code>. This way
mentioned <code class="language-plaintext highlighter-rouge">ConcurrentHashMap</code> is growing with every new <code class="language-plaintext highlighter-rouge">key</code> passed to the <code class="language-plaintext highlighter-rouge">getValueForKey</code> method.</p>

<p>If you have a heap memory leak in your application, then you have two groups of objects:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/leak-1.png" alt="alt text" title="leak"></p>

<ul>
  <li><strong>Live set</strong> - a group of objects that are still needed by your application</li>
  <li><strong>Memory leak</strong> - a group of objects that are no longer needed</li>
</ul>

<p>Garbage collectors cannot free the second group if there is at least one strong reference from the <strong>live set</strong> to the <strong>memory
leak</strong>. The biggest problems with diagnosing memory leaks are:</p>

<ul>
  <li>the fact that the object was created <strong>is not an issue</strong> - it was created because it was needed for something</li>
  <li>the fact that the mentioned reference was created <strong>is not an issue</strong> - it had some purpose too</li>
  <li>we need to understand why that reference was not removed from our application</li>
</ul>

<p>The last one is not trivial. All the observability/profiling tools give us a great possibility to understand why
some event has happened, but with memory leaks, we need to understand why something has not yet happened.
Two additional tools come to our rescue:</p>

<ul>
  <li><strong>heap dump</strong> - shows us the current state of a heap - we can find out what kind of objects are there but shouldn’t be</li>
  <li><strong>profiler</strong> - shows us where these objects were created</li>
</ul>

<p>In this simple example, any of those tools is enough. In more complicated ones, I needed both to find the root cause
of the problem. It is nice to finally have a tool that can profile memory leaks on production systems.</p>

<p>It is worth mentioning that the <code class="language-plaintext highlighter-rouge">--live</code> option is available only since <strong>async-profiler 2.9</strong>, it needs 
<strong>JDK &gt;= 11</strong> and might still contain bugs. I didn’t have a chance to test it on any production system yet.</p>

<h3 id="locks">Locks</h3>

<p>Async-profiler has a lock mode. This mode is useful when looking into look contention in our application.
Let’s try to use it and understand the internals of <code class="language-plaintext highlighter-rouge">ConcurrentHashMap</code>.  The
<code class="language-plaintext highlighter-rouge">get()</code> method is obviously lock-free, but what about <code class="language-plaintext highlighter-rouge">computeIfAbsent()</code>? 
Let’s profile a code that uses it:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">LockService</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">map</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ConcurrentHashMap</span><span class="o">&lt;&gt;();</span>
  
    <span class="nc">LockService</span><span class="o">()</span> <span class="o">{</span>
        <span class="nc">String</span> <span class="n">a</span> <span class="o">=</span> <span class="s">"AaAa"</span><span class="o">;</span>
        <span class="nc">String</span> <span class="n">b</span> <span class="o">=</span> <span class="s">"BBBB"</span><span class="o">;</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Hashcode equals: {}"</span><span class="o">,</span> <span class="n">a</span><span class="o">.</span><span class="na">hashCode</span><span class="o">()</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="na">hashCode</span><span class="o">());</span> <span class="c1">// true</span>
        <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">a</span><span class="o">);</span>
        <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">b</span><span class="o">);</span>
    <span class="o">}</span>
  
    <span class="kt">void</span> <span class="nf">withLock</span><span class="o">(</span><span class="nc">String</span> <span class="n">key</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">key</span><span class="o">);</span>
    <span class="o">}</span>
  
    <span class="kt">void</span> <span class="nf">withoutLock</span><span class="o">(</span><span class="nc">String</span> <span class="n">key</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">map</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">key</span><span class="o">)</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">key</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Let’s use lock mode to profile that:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># preparation</span>
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 1 http://localhost:8081/examples/lock/with-lock
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 1 http://localhost:8081/examples/lock/without-lock

<span class="c"># profiling</span>
./profiler.sh start <span class="nt">-e</span> lock <span class="nt">-f</span> lock.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 100000 <span class="nt">-c</span> 100 http://localhost:8081/examples/lock/with-lock
ab <span class="nt">-n</span> 100000 <span class="nt">-c</span> 100 http://localhost:8081/examples/lock/without-lock
./profiler.sh stop <span class="nt">-f</span> lock.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The lock flame graph: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/lock.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/lock-1.png" alt="alt text" title="flames"></p>

<p>I highlighted the <code class="language-plaintext highlighter-rouge">LockController</code> occurrence. Let’s zoom it:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/lock-2.png" alt="alt text" title="flames"></p>

<p>We see that only the <code class="language-plaintext highlighter-rouge">withLock()</code> method acquires locks. You can study the internals of the <code class="language-plaintext highlighter-rouge">computeIfAbsent()</code> method
to see that it might lock on hash collisions. 
The easiest way to confirm this is by creating a small program that triggers hash collisions on purpose.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">map</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ConcurrentHashMap</span><span class="o">&lt;&gt;();</span>
    <span class="nc">String</span> <span class="n">a</span> <span class="o">=</span> <span class="s">"AaAa"</span><span class="o">;</span>
    <span class="nc">String</span> <span class="n">b</span> <span class="o">=</span> <span class="s">"BBBB"</span><span class="o">;</span>

    <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">a</span><span class="o">);</span>

    <span class="c1">// it enters the synchronized section here</span>
    <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">b</span><span class="o">);</span>

    <span class="c1">// it enters the synchronized section here, and all the following</span>
    <span class="c1">// execution of computeIfAbsent with "BBBB" as a key.</span>
    <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">b</span><span class="o">);</span>
    <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">b</span><span class="o">);</span>
    <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">b</span><span class="o">);</span>
    <span class="n">map</span><span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="n">b</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>If you observe a considerable lock contention in this method, and most of the 
time a key is already in the map; then you may consider the approach used in the <code class="language-plaintext highlighter-rouge">withoutLock()</code> method.</p>

<h2 id="tts">Time to safepoint</h2>

<p>The common misconception in the Java world is that <em>garbage collectors</em> need a Stop-the-world (STW) phase to clean dead objects:
But <strong>not only GC needs it</strong>. Other internal mechanisms require application threads to be paused.
For example, the JVM needs an STW phase to <em>deoptimize</em> some compilations and to revoke <em>biased locks</em>. Let’s get a closer look at how the
STW phase works.</p>

<p>On our JVM, there are running some application threads:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/1.png" alt="alt text" title="chart 1"></p>

<p>While running those threads from time to time, JVM needs to do some work in the STW phase. So it starts this phase, with a
<em>global safepoint request</em>, which informs every thread to go to “sleep”:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/2.png" alt="alt text" title="chart 2"></p>

<p>Every thread has to find out about this.
Stopping at a safepoint is cooperative: Each thread checks at certain 
points in the code if it needs to suspend.
The time in which threads will be aware of an STW phase is different for
 every thread. 
Every thread has to wait for the slowest one. The time between starting 
an STW phase, and the slowest thread suspension, is called
<em>time to safepoint</em>:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/3.png" alt="alt text" title="chart 3"></p>

<p>JVM threads can do the work that needs the STW phase only after every
 thread is asleep. The time when all application threads sleep, 
is called <em>safepoint operation time</em>:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/4.png" alt="alt text" title="chart 4"></p>

<p>When the JVM finishes its work, application threads are wakened up:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/5_002.png" alt="alt text" title="chart 5"></p>

<p>If the application suffers from long STW phases, then most of the 
time, those are GC cycles, and that information can be found
in the GC logs or JFR. But the situation is more tricky if the 
application has one thread that slows down every other from reaching the
 safepoint.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># preparation</span>
curl http://localhost:8081/examples/tts/start
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 1 http://localhost:8081/examples/tts/execute

<span class="c"># profiling</span>
./profiler.sh start <span class="nt">--ttsp</span> <span class="nt">-f</span> tts.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 1 http://localhost:8081/examples/tts/execute
./profiler.sh stop <span class="nt">-f</span> tts.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>In safepoint logs (you need to run your JVM with the <code class="language-plaintext highlighter-rouge">-Xlog:safepoint</code> flag), we can see:</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>105,372s][info <span class="o">][</span>safepoint   <span class="o">]</span> Safepoint <span class="s2">"ThreadDump"</span>, Time since last: 156842 ns, Reaching safepoint: 13381 ns, At safepoint: 120662 ns, Total: 134043 ns
<span class="o">[</span>105,372s][info <span class="o">][</span>safepoint   <span class="o">]</span> Safepoint <span class="s2">"ThreadDump"</span>, Time since last: 157113 ns, Reaching safepoint: 14738 ns, At safepoint: 120252 ns, Total: 134990 ns
<span class="o">[</span>105,373s][info <span class="o">][</span>safepoint   <span class="o">]</span> Safepoint <span class="s2">"ThreadDump"</span>, Time since last: 157676 ns, Reaching safepoint: 13700 ns, At safepoint: 120487 ns, Total: 134187 ns
<span class="o">[</span>105,402s][info <span class="o">][</span>safepoint   <span class="o">]</span> Safepoint <span class="s2">"ThreadDump"</span>, Time since last: 159020 ns, Reaching safepoint: 29524545 ns, At safepoint: 160702 ns, Total: 29685247 ns
</code></pre></div></div>

<p><em>Reaching safepoint</em> contains the time to safepoint. Most of the time, it is <strong>&lt;15 ms</strong>, but we also see one outlier:
<strong>29 ms</strong>. Async-profiler in <code class="language-plaintext highlighter-rouge">--ttsp</code> mode collects samples between:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">SafepointSynchronize::begin</code>, and</li>
  <li><code class="language-plaintext highlighter-rouge">RuntimeService::record_safepoint_synchronized</code></li>
</ul>

<p>During that time, our application threads are trying to reach a safepoint:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/tts.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/tts.png" alt="alt text" title="flames"></p>

<p>We can see that most of the gathered samples are executing <code class="language-plaintext highlighter-rouge">arraycopy</code>, invoked from <code class="language-plaintext highlighter-rouge">TtsController</code>.
The time to safepoint issues that I have approached so far are:</p>

<ul>
  <li><strong>arraycopy</strong> - as in our example</li>
  <li><strong>old JDK + loops</strong> - since JDK 11u4 we have an <em>loop strip mining</em> optimization working correctly (after fixing
<a href="https://bugs.java.com/bugdatabase/view_bug.do?bug_id=JDK-8220374" target="_blank">JDK-8220374</a>), before that if you had
a counted loop, it could be compiled without any check for safepoint</li>
  <li><strong>swap</strong> - when your application thread executes some work in <em>thread_in_vm</em> state (after calling some native method),<br>
and during that execution, it waits for some pages to be swapped in/out, which can slow down reaching the safepoint</li>
</ul>

<p>The solution for the <strong>arraycopy</strong> issue is to copy larger arrays by some custom method, which might use <strong>arraycopy</strong> for smaller sub-arrays. 
It will be a bit slower, but it will not slow down the whole application when reaching a safepoint is required.</p>

<p>For the <strong>swap</strong> issue, just disable the swap.</p>

<h2 id="methods">Methods</h2>

<p>Async-profiler can instrument a method so that we can see all the stack traces with this method on the top.
To achieve that, async-profiler uses instrumentation.</p>

<p><strong>Big warning</strong>: It’s already pointed out in the README of the profiler that if you are not running
the profiler from <code class="language-plaintext highlighter-rouge">agentpath</code>, then the first instrumentation of a Java method can result in a code
cache flush. It’s not the fault of the async-profiler; it’s the nature of all instrumentation-based profilers 
combined with JVM’s code. Here is a comment from the <a href="https://github.com/openjdk/jdk/blob/master/src/hotspot/share/prims/jvmtiRedefineClasses.cpp#L4078" target="_blank">JVM sources</a>:</p>

<p>// Deoptimize all compiled code that depends on the classes redefined.
//
// If the can_redefine_classes capability is obtained in the onload
// phase then the compiler has recorded all dependencies from startup.
// In that case we need only deoptimize and throw away all compiled code
// that depends on the class.
//
// If can_redefine_classes is obtained sometime after the onload
// phase then the dependency information may be incomplete. In that case
// the first call to RedefineClasses causes all compiled code to be
// thrown away. As can_redefine_classes has been obtained then
// all future compilations will record dependencies so second and
// subsequent calls to RedefineClasses need only throw away code
// that depends on the class.</p>

<p>You can check the <a href="https://github.com/jvm-profiling-tools/async-profiler/pull/483#discussion_r735019623" target="_blank">README PR</a>
discussion for more information on this topic. But let’s focus on the usage of the mode for our purposes.
In this case, we could easily do it with a plain IDE debugger, but there are situations where something
is happening only in one environment, or we are tracing some issues we do not know how to reproduce.</p>

<p>Since Spring beans are usually created during applications startup, let’s run our application that way:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="se">\</span>
<span class="nt">-agentpath</span>:/path/to/libasyncProfiler.so<span class="o">=</span>start,event<span class="o">=</span><span class="s2">"org.springframework.web.filter.AbstractRequestLoggingFilter.&lt;init&gt;"</span> <span class="se">\</span>
<span class="nt">-jar</span> first-application/target/first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">AbstractRequestLoggingFilter.&lt;init&gt;</code> is simply a constructor. We are trying to find out
where such an object is created. After our application is started, we can execute such a command
in the profiler directory:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./profiler.sh stop first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>It will print us to one stack trace:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">---</span> Execution profile <span class="nt">---</span>
Total samples       : 1

<span class="nt">---</span> 1 calls <span class="o">(</span>100.00%<span class="o">)</span>, 1 sample
  <span class="o">[</span> 0] org.springframework.web.filter.AbstractRequestLoggingFilter.&lt;init&gt;
  <span class="o">[</span> 1] org.springframework.web.filter.CommonsRequestLoggingFilter.&lt;init&gt;
  <span class="o">[</span> 2] com.example.firstapplication.examples.alloc.AllocConfiguration<span class="nv">$1</span>.&lt;init&gt;
  <span class="o">[</span> 3] com.example.firstapplication.examples.alloc.AllocConfiguration.requestLoggingFilter
  <span class="o">[</span> 4] com.example.firstapplication.examples.alloc.AllocConfiguration<span class="nv">$$</span>SpringCGLIB<span class="nv">$$</span>0.CGLIB<span class="nv">$requestLoggingFilter$0</span>
  <span class="o">[</span> 5] com.example.firstapplication.examples.alloc.AllocConfiguration<span class="nv">$$</span>SpringCGLIB<span class="nv">$$</span>2.invoke
...
  <span class="o">[</span>24] org.springframework.beans.factory.support.AbstractBeanFactory.getBean
...
  <span class="o">[</span>33] org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup
...
  <span class="o">[</span>58] org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;
...
  <span class="o">[</span>78] org.springframework.boot.loader.JarLauncher.main

       calls  percent  samples  top
  <span class="nt">----------</span>  <span class="nt">-------</span>  <span class="nt">-------</span>  <span class="nt">---</span>
           1  100.00%        1  org.springframework.web.filter.AbstractRequestLoggingFilter.&lt;init&gt;
</code></pre></div></div>

<p>We have all the information that we need. The object is created in <code class="language-plaintext highlighter-rouge">AllocConfiguration</code> during
creation of <code class="language-plaintext highlighter-rouge">CommonsRequestLoggingFilter</code> bean.</p>

<p>One of the other use cases where I used to use method profiling was finding memory leaks. 
I knew which types were leaking from the heap dump, and with method profiling, I could see where objects 
of these types were created. Consider this a fallback when the <a href="#alloc-live">dedicated mode</a> does
not work.</p>

<h2 id="methods-native">Native functions</h2>

<p>Not only can you trace Java code with the async-profiler but also a native one. That way of profiling doesn’t cause
deoptimizations.</p>

<p>Some native functions are worth a better look; let’s cover them quickly.</p>

<h3 id="methods-ex">Exceptions</h3>

<p>How many exceptions should be thrown if your application works 
without any outage/downtime and everything is stable? Exceptions should 
be thrown if something unexpected happens.
Unfortunately, I saw an application that used the exception-control-flow
 approach
more common in languages like Python. Creating a new
exception is a CPU-intensive operation since, by default, it fills the 
stack trace. 
I once saw an application that consumed <strong>~15%</strong> of its CPU time on just
creating new exceptions. You can use async-profiler in method mode with 
event <code class="language-plaintext highlighter-rouge">Java_java_lang_Throwable_fillInStackTrace</code> if you want to see where exceptions are created.</p>

<p>Let’s start our application with profiler enabled from the start to see also how many
exceptions are thrown during the startup of a Spring Boot application, just for fun:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="se">\</span>
<span class="nt">-agentpath</span>:/path/to/libasyncProfiler.so<span class="o">=</span>start,jfr,file<span class="o">=</span>exceptions.jfr,event<span class="o">=</span><span class="s2">"Java_java_lang_Throwable_fillInStackTrace"</span> <span class="se">\</span>
<span class="nt">-jar</span> first-application/target/first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>After the startup, let’s run:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 1 http://localhost:8081/examples/exc/
./profiler.sh stop <span class="nt">-f</span> exceptions.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The flame graph is too large to post it here as an image, sorry. Spring Boot, in that case,
threw <strong>12478</strong> exceptions. You can play with <a href="https://krzysztofslusarski.github.io/assets/async-demos/exceptions.html" target="_blank">HTML</a>.
Let’s focus on our synthetic controller:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/exceptions.png" alt="alt text" title="flames"></p>

<p>Source code of the controller:</p>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@GetMapping</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span>
<span class="nc">String</span> <span class="nf">flowControl</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">ThreadLocalRandom</span> <span class="n">random</span> <span class="o">=</span> <span class="nc">ThreadLocalRandom</span><span class="o">.</span><span class="na">current</span><span class="o">();</span>
    <span class="k">try</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(!</span><span class="n">random</span><span class="o">.</span><span class="na">nextBoolean</span><span class="o">())</span> <span class="o">{</span>
            <span class="k">throw</span> <span class="k">new</span> <span class="nf">IllegalArgumentException</span><span class="o">(</span><span class="s">"Random returned false"</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">IllegalArgumentException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="s">"EXC"</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="k">return</span> <span class="s">"OK"</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>If you care about performance, don’t use the exception-control-flow approach. If you really need such a code,
reuse exception options like ANTLR or create an exception constructor that doesn’t fill the stack trace:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**
 * Constructs a new exception with the specified detail message,
 * cause, suppression enabled or disabled, and writable stack
 * trace enabled or disabled.
 *
 * @param  message the detail message.
 * @param cause the cause.  (A {@code null} value is permitted,
 * and indicates that the cause is nonexistent or unknown.)
 * @param enableSuppression whether or not suppression is enabled
 *                          or disabled
 * @param writableStackTrace whether or not the stack trace should
 *                           be writable
 * @since 1.7
 */</span>
<span class="kd">protected</span> <span class="nf">Exception</span><span class="o">(</span><span class="nc">String</span> <span class="n">message</span><span class="o">,</span> <span class="nc">Throwable</span> <span class="n">cause</span><span class="o">,</span>
                    <span class="kt">boolean</span> <span class="n">enableSuppression</span><span class="o">,</span>
                    <span class="kt">boolean</span> <span class="n">writableStackTrace</span><span class="o">)</span> <span class="o">{</span>
    <span class="kd">super</span><span class="o">(</span><span class="n">message</span><span class="o">,</span> <span class="n">cause</span><span class="o">,</span> <span class="n">enableSuppression</span><span class="o">,</span> <span class="n">writableStackTrace</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Just set <code class="language-plaintext highlighter-rouge">writableStackTrace</code> to <code class="language-plaintext highlighter-rouge">false</code>. It will be rather ugly but faster.</p>

<h3 id="methods-g1ha">G1GC humongous allocation</h3>

<p>We already saw how to detect humongous objects with allocation mode. Since
async-profiler can also instrument JVM code, and allocations of a humongous objects are 
nothing else than invocations of C++ code, we can take advantage of that.
If you want to check where humongous objects are allocated, you can use native functions mode
with event <code class="language-plaintext highlighter-rouge">G1CollectedHeap::humongous_obj_allocate</code>. This approach may have lower
overhead but won’t give you sizes of allocated objects.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># little warmup</span>
ab <span class="nt">-n</span> 2 <span class="nt">-c</span> 1 http://localhost:8081/examples/alloc/

<span class="c"># profiling time</span>
./profiler.sh start <span class="nt">-e</span> <span class="s2">"G1CollectedHeap::humongous_obj_allocate"</span> <span class="nt">-f</span> humongous.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000 <span class="nt">-c</span> 1 http://localhost:8081/examples/alloc/
./profiler.sh stop <span class="nt">-f</span> humongous.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The flame graph is almost the same as in <code class="language-plaintext highlighter-rouge">alloc</code> mode; we can see some JVM yellow frames this time too:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/humongous.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/humongous.png" alt="alt text" title="flames"></p>

<h3 id="methods-thread">Thread start</h3>

<p>Starting a platform thread is an expensive operation too. The number of started 
threads can be easily monitored with any JMX-based monitoring tool like JMC. Here is the MBean
with the value of all the created threads:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java.lang:type<span class="o">=</span>Threading 
<span class="nv">attribute</span><span class="o">=</span>TotalStartedThreadCount
</code></pre></div></div>

<p>If you monitor that value and the chart like that:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/threads-2.png" alt="alt text" title="threads"></p>

<p>Then you might want to check who is creating those short-living threads:
We use async-profiler with the <code class="language-plaintext highlighter-rouge">JVM_StartThread</code> event in native functions mode for this purpose:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># little warmup</span>
ab <span class="nt">-n</span> 100 <span class="nt">-c</span> 1 http://localhost:8081/examples/thread/

<span class="c"># profiling time</span>
./profiler.sh start <span class="nt">-e</span> <span class="s2">"JVM_StartThread"</span> <span class="nt">-f</span> threads.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000 <span class="nt">-c</span> 1 http://localhost:8081/examples/thread/
./profiler.sh stop <span class="nt">-f</span> threads.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The flame graph:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/threads.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/threads-1.png" alt="alt text" title="flames"></p>

<p>This flame graph is not really complicated. But it is only a small example.
In real life, such flame graphs are larger.</p>

<p>The code responsible for the thread creation observed in the flame graph is the following:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@SneakyThrows</span>
<span class="nd">@GetMapping</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span>
<span class="nc">String</span> <span class="nf">doInNewThread</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">ExecutorService</span> <span class="n">threadPool</span> <span class="o">=</span> <span class="nc">Executors</span><span class="o">.</span><span class="na">newFixedThreadPool</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
    <span class="k">return</span> <span class="n">threadPool</span><span class="o">.</span><span class="na">submit</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="k">return</span> <span class="s">"OK"</span><span class="o">;</span>
    <span class="o">}).</span><span class="na">get</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div></div>

<p>And yes, I saw such a pattern in a real production application. The intention was to have a
fixed thread pool and delegate tasks to it, but by mistake, someone created that pool for
every request.</p>

<h3 id="methods-classes">Class loading</h3>

<p>Similar to creating short-living threads, I saw an application that created plenty of
short-living class definitions. I know there are some use cases for such behavior,
But it has been an accident in this case. You can monitor the number of loaded classes
with JMX:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java.lang:type<span class="o">=</span>ClassLoading
<span class="nv">attribute</span><span class="o">=</span>TotalLoadedClassCount
</code></pre></div></div>

<p>There are some internals of the JVM, like reflection or debugging, which are used in a variety of frameworks, that can generate
new class definitions during runtime: So increasing that number (even after warmup) 
doesn’t mean that we have a problem already. But if <code class="language-plaintext highlighter-rouge">TotalLoadedClassCount</code> is much higher 
than <code class="language-plaintext highlighter-rouge">LoadedClassCount</code>, then we might have a problem. You can find the creator of those classes with method mode and 
the event: <code class="language-plaintext highlighter-rouge">Java_java_lang_ClassLoader_defineClass1</code>.</p>

<p>To be honest, I saw such an issue only once and cannot reproduce it now. Making a
synthetic example for this use-case seems wrong, so I will just keep you with the knowledge
that there is such a possibility, especially if you purposefully create classes dynamically.</p>

<h2 id="perf">Perf events</h2>

<p>Async-profiler can also help you with low-level diagnosis where you want to correlate perf
events with Java code:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">context-switches</code> - to find out which parts of your Java code do context switching</li>
  <li><code class="language-plaintext highlighter-rouge">cache-misses</code> - which part of your code can stall due to cache misses - this information is harder to analyze if you have many
context switches</li>
  <li><code class="language-plaintext highlighter-rouge">LLC-load-misses</code>- which part of your code needs a lot of data directly from RAM which is not cached</li>
  <li>…</li>
</ul>

<p>I want to describe the three in more detail in the following.</p>

<h3 id="perf-cache">Cache misses</h3>

<p>Let’s return to the example with matrix multiplication from the <a href="#cpu-hard">CPU - a bit harder</a>
 section.
I usually start by looking at basic CPU performance counters to see what
 our CPU is doing in the slow and the fast multiplication.
This is the textbook example of cache misses and their importance for 
performance.
I like to start with the JMH test to profile the specific code properly.</p>

<p>I’ve prepared such a benchmark in the <code class="language-plaintext highlighter-rouge">jmh-suite</code> module. Let’s run it with the perf profiler:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-jar</span> jmh-suite/target/benchmarks.jar <span class="nt">-prof</span> perf
</code></pre></div></div>

<p>The fast algorithm (I’ve cut the output to the most interesting metrics):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         20 544,42 msec task-clock                       #    1,008 CPUs utilized          
    49 510 157 799      L1-dcache-loads                  #    2,410 G/sec                    (38,55%)
     9 300 675 824      L1-dcache-load-misses            #   18,79% of all L1-dcache accesses  (38,55%)
     1 635 877 333      LLC-loads                        #   79,626 M/sec                    (30,80%)
        27 833 149      LLC-load-misses                  #    1,70% of all LL-cache accesses  (30,76%)
</code></pre></div></div>

<p>The slow one:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         22 291,74 msec task-clock                       #    1,008 CPUs utilized          
    71 632 332 204      L1-dcache-loads                  #    3,213 G/sec                    (38,51%)
    29 718 804 848      L1-dcache-load-misses            #   41,49% of all L1-dcache accesses  (38,50%)
     6 909 042 687      LLC-loads                        #  309,937 M/sec                    (30,79%)
        10 043 405      LLC-load-misses                  #    0,15% of all LL-cache accesses  (30,79%)
</code></pre></div></div>

<p>The slower algorithm has <strong>three times</strong> more L1 data cache misses and over <strong>four times</strong> more last-level
cache loads. We can now use async-profiler in three different modes:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-jar</span> jmh-suite/target/benchmarks.jar <span class="nt">-prof</span> async:libPath<span class="o">=</span>/path/to/libasyncProfiler.so<span class="se">\;</span><span class="nv">event</span><span class="o">=</span>cache-misses<span class="se">\;</span><span class="nv">output</span><span class="o">=</span>jfr
java <span class="nt">-jar</span> jmh-suite/target/benchmarks.jar <span class="nt">-prof</span> async:libPath<span class="o">==</span>/path/to/libasyncProfiler.so<span class="se">\;</span><span class="nv">event</span><span class="o">=</span>L1-dcache-load-misses<span class="se">\;</span><span class="nv">output</span><span class="o">=</span>jfr
java <span class="nt">-jar</span> jmh-suite/target/benchmarks.jar <span class="nt">-prof</span> async:libPath<span class="o">==</span>/path/to/libasyncProfiler.so<span class="se">\;</span><span class="nv">event</span><span class="o">=</span>LLC-load-misses<span class="se">\;</span><span class="nv">output</span><span class="o">=</span>jfr
</code></pre></div></div>

<p>All three flame graphs are very similar; let’s take a look at <code class="language-plaintext highlighter-rouge">cache-misses</code>: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/cache-misses.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cache-misses.png" alt="alt text" title="flames"></p>

<p>I added the line numbers this time, so we could see exactly where the problem was. <strong>~82%</strong> of cache misses
occurred in the same line:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span><span class="o">]</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
</code></pre></div></div>

<p>This line is nested inside three loops. The order of loops is <code class="language-plaintext highlighter-rouge">i, j, k</code>. If we unroll the last loop four times
we would get the following:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">0</span><span class="o">]</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">0</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
<span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="o">]</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
<span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="o">]</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
<span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">3</span><span class="o">]</span> <span class="o">*</span> <span class="n">b</span><span class="o">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">3</span><span class="o">][</span><span class="n">j</span><span class="o">];</span>
</code></pre></div></div>

<p>Let’s look at this code from a memory layout perspective. The array <code class="language-plaintext highlighter-rouge">a[i]</code> is a contiguous part of memory. That’s how Java
allocates arrays. Elements <code class="language-plaintext highlighter-rouge">a[i][k + 0]</code> … <code class="language-plaintext highlighter-rouge">a[i][k + 3]</code> are very close to each other and are loaded 
sequentially. The CPU loads small blocks of memory from RAM into the cache if the block is not already there.
Accessing data in a sequential pattern is, therefore, far less expensive.</p>

<p>The access pattern to table  <code class="language-plaintext highlighter-rouge">b</code> is completely different. The <code class="language-plaintext highlighter-rouge">b[k + x]</code> is just a pointer to a table. It is 
somewhere on the heap, but where exactly? Well, we cannot control that. Element <code class="language-plaintext highlighter-rouge">b[k + 0][j]</code> may be in a completely
different place than <code class="language-plaintext highlighter-rouge">b[k + 1][j]</code>. That’s unfortunate for the CPU. This is why the speed difference between 
both matrix multiplications is not as large as expected.</p>

<p>Memory access patterns are the key here. The <code class="language-plaintext highlighter-rouge">matrixMultiplyFaster</code> algorithm accesses the table <code class="language-plaintext highlighter-rouge">a</code> mostly sequentially, which is why it’s faster.</p>

<p>I don’t want to go into detail about what is happening in the CPU 
with these algorithms. This post aims to teach the usage of 
async-profiler, not CPU architecture and algorithm engineering. If you 
want to go deeper with that knowledge, a very
good book for a start is 
<a href="https://book.easyperf.net/perf_book" target="_blank">Denis Bakhvalov - Performance Analysis and Tuning on Modern CPUs</a>.
It’s not about Java, but I cannot recommend any Java-centric book 
related to CPU architecture, as it’s still a relatively niche topic.
I know that two very good performance engineers are writing one now. 
When it is published, I will paste a link here.</p>

<h3 id="perf-pf">Page faults</h3>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/page-fault-1.png" alt="alt text" title="page"></p>

<p>Every process running on Linux contains its own virtual memory. If a process needs more
memory, it invokes functions like <code class="language-plaintext highlighter-rouge">malloc</code> or <code class="language-plaintext highlighter-rouge">mmap</code>. The OS guarantees the returned memory to be readable/writable by the current process.
But this does not mean that any block of physical RAM has been reserved for the process.</p>

<p>The OS is smart enough to decide whether that fault should be converted into a SEGFAULT or should trigger the kernel
to map RAM to the process’s virtual memory because it was previously promised to the process.</p>

<p>Java is a process from an OS perspective, nothing less, nothing more. Knowing that we can trace
<code class="language-plaintext highlighter-rouge">page fault</code> events to detect why our application consumes more RAM. It may be a native memory 
leak or some framework/library/JVM bug.</p>

<p>But this is not perfect for tracing leaks since it shows every request for additional RAM,
including ones that may be freed in the future. I know that Andrei Pangin is working
on a native memory leak detector that will trace allocations that haven’t been freed, but for
now, that feature is not in the latest release.</p>

<p>As an example, let’s run our application with and without <code class="language-plaintext highlighter-rouge">-XX:+AlwaysPreTouch</code>,
forcing the JVM to access all allocated memory after requesting it from the OS.
This allows us to find where Java needs more RAM after startup. We will use the heap memory leak that we used
before:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-Xmx1G</span> <span class="nt">-Xms1G</span> <span class="nt">-XX</span>:+AlwaysPreTouch <span class="se">\</span>
<span class="nt">-jar</span> first-application/target/first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>In the other console, let’s do the following:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ab <span class="nt">-n</span> 10000 <span class="nt">-c</span> 4 http://localhost:8081/examples/leak/do-leak

./profiler.sh start <span class="nt">-e</span> page-faults <span class="nt">-f</span> page-faults-apt-on.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000000 <span class="nt">-c</span> 4 http://localhost:8081/examples/leak/do-leak
./profiler.sh stop <span class="nt">-f</span> page-faults-apt-on.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>Now let’s do the same without <code class="language-plaintext highlighter-rouge">-XX:+AlwaysPreTouch</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-Xmx1G</span> <span class="nt">-Xms1G</span> <span class="se">\</span>
<span class="nt">-jar</span> first-application/target/first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>In the other console, let’s execute the following:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ab <span class="nt">-n</span> 10000 <span class="nt">-c</span> 4 http://localhost:8081/examples/leak/do-leak

./profiler.sh start <span class="nt">-e</span> page-faults <span class="nt">-f</span> page-faults-apt-off.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000000 <span class="nt">-c</span> 4 http://localhost:8081/examples/leak/do-leak
./profiler.sh stop <span class="nt">-f</span> page-faults-apt-off.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>Flame graph without <code class="language-plaintext highlighter-rouge">-XX:+AlwaysPreTouch</code>: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/page-faults-apt-off.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/page-faults-apt-off.png" alt="alt text" title="flames"></p>

<p>Most of the need for additional RAM is acquired in GC threads, but there are some page faults in our Java code
(big green flame). These page faults can hurt your performance and make your latency less
predictable.</p>

<p>Flame graph with <code class="language-plaintext highlighter-rouge">-XX:+AlwaysPreTouch</code>: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/page-faults-apt-on.html" target="_blank">HTML</a>)
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/page-faults-apt-on.png" alt="alt text" title="flames"></p>

<p>Almost all the frames needing additional RAM now belong to compiler threads. This is due
the code heap growing with the compilation of new methods.</p>

<p>I was able to isolate and recreate the memory leak that I described in
<a href="https://bugs.openjdk.org/browse/JDK-8240723" target="_blank">JDK-8240723</a> with that mode.</p>

<h3 id="perf-cycles">Cycles</h3>

<p>If you need better visibility of what your kernel is doing, then you may consider choosing the
<code class="language-plaintext highlighter-rouge">cycles</code> event instead of <code class="language-plaintext highlighter-rouge">cpu</code>. This may be useful for low-latency applications
or while chasing bugs in the kernel (those also exist). Let’s see the difference:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># warmup</span>
curl <span class="nt">-v</span> http://localhost:8081/examples/cycles/

<span class="c"># profiling</span>
./profiler.sh start <span class="nt">-e</span> cpu <span class="nt">-f</span> cycles-cpu.jfr first-application-0.0.1-SNAPSHOT.jar
curl <span class="nt">-v</span> http://localhost:8081/examples/cycles/
./profiler.sh stop <span class="nt">-f</span> cycles-cpu.jfr first-application-0.0.1-SNAPSHOT.jar
./profiler.sh start <span class="nt">-e</span> cycles <span class="nt">-f</span> cycles-cycles.jfr first-application-0.0.1-SNAPSHOT.jar
curl <span class="nt">-v</span> http://localhost:8081/examples/cycles/
./profiler.sh stop <span class="nt">-f</span> cycles-cycles.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The flame graph for <code class="language-plaintext highlighter-rouge">cpu</code> profiling:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/cycles-cpu.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cycles-cpu.png" alt="alt text" title="flames"></p>

<p>Corresponding profile for <code class="language-plaintext highlighter-rouge">cycles</code> event:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/cycles-cycles.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cycles-cycles.png" alt="alt text" title="flames"></p>

<p>As we can see, the <code class="language-plaintext highlighter-rouge">cycles</code> profile is more detailed.</p>

<h2 id="single-req">Filtering single request</h2>

<h3 id="single-req-why">Why aggregated results are not enough</h3>

<p>So far, we have been looking at the profile of a whole application. But what if the app works well
but there are some slower requests from time to time, and we want to know why? In such an application,
where one request is handled by one thread, we can extract the profile of a single request. The JFR file contains
all the information needed; we just need to filter them out. To do it, we need to have a log
that will tell us which thread was responsible for the execution of the request at the time of the
execution. Tomcat, embedded into Spring Boot, has access logs with all that information.</p>

<p>I configured our example application with access logs in the format:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>%t] <span class="o">[</span>%r] <span class="o">[</span>%s] <span class="o">[</span>%D ms] <span class="o">[</span>%I]
</code></pre></div></div>

<p>Here is a short explanation of that magic:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">%t</code> - time of finishing handling of the request</li>
  <li><code class="language-plaintext highlighter-rouge">%r</code> - requested URI</li>
  <li><code class="language-plaintext highlighter-rouge">%s</code> - response status code</li>
  <li><code class="language-plaintext highlighter-rouge">%D</code> - duration time in milliseconds</li>
  <li><code class="language-plaintext highlighter-rouge">%I</code> - thread that handled request</li>
</ul>

<p>Let’s see it in action.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># warmup</span>
ab <span class="nt">-n</span> 20 <span class="nt">-c</span> 4 http://localhost:8081/examples/filtering/

<span class="c"># profiling of the first request</span>
./profiler.sh start <span class="nt">-e</span> wall <span class="nt">-f</span> filtering.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 50 <span class="nt">-c</span> 4 http://localhost:8081/examples/filtering/
./profiler.sh stop <span class="nt">-f</span> filtering.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>In the access logs, we can spot faster and slower requests:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>05/Dec/2022:18:41:57 +0100] <span class="o">[</span>GET /examples/filtering/ HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1044 ms] <span class="o">[</span>http-nio-8081-exec-2]
<span class="o">[</span>05/Dec/2022:18:41:57 +0100] <span class="o">[</span>GET /examples/filtering/ HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>2779 ms] <span class="o">[</span>http-nio-8081-exec-5]
<span class="o">[</span>05/Dec/2022:18:41:58 +0100] <span class="o">[</span>GET /examples/filtering/ HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1048 ms] <span class="o">[</span>http-nio-8081-exec-8]
<span class="o">[</span>05/Dec/2022:18:41:58 +0100] <span class="o">[</span>GET /examples/filtering/ HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1052 ms] <span class="o">[</span>http-nio-8081-exec-9]
<span class="o">[</span>05/Dec/2022:18:41:59 +0100] <span class="o">[</span>GET /examples/filtering/ HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>2829 ms] <span class="o">[</span>http-nio-8081-exec-7]
<span class="o">[</span>05/Dec/2022:18:41:59 +0100] <span class="o">[</span>GET /examples/filtering/ HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1058 ms] <span class="o">[</span>http-nio-8081-exec-1]
</code></pre></div></div>

<p>Let’s load the JFR into my viewer and look at the flame graph of the whole application:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/filtering-1.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/filtering-1.png" alt="alt text" title="flames"></p>

<p>It’s hard to guess why some requests are slower than others. We can see two different
methods executed at the top of the flame graph:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">matrixMultiplySlow()</code></li>
  <li><code class="language-plaintext highlighter-rouge">matrixMultiplyFaster()</code></li>
</ul>

<p>We cannot conclude from that which one is responsible for worse latency. 
Let’s add filters to that graph to understand the latency of the second request from pasted access log:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[05/Dec/2022:18:41:57 +0100] [GET /examples/filtering/ HTTP/1.0] [200] [2779 ms] [http-nio-8081-exec-5]
</code></pre></div></div>

<ul>
  <li><em>Access log filter</em>:
    <ul>
      <li><em>End date</em> - <code class="language-plaintext highlighter-rouge">05/Dec/2022:18:41:57 +0100</code></li>
      <li><em>End date format</em> - let’s keep the default one</li>
      <li><em>Duration</em> - <code class="language-plaintext highlighter-rouge">2779</code></li>
      <li><em>Locale language</em> - <code class="language-plaintext highlighter-rouge">EN</code></li>
    </ul>
  </li>
  <li><em>Thread filter</em> - <code class="language-plaintext highlighter-rouge">http-nio-8081-exec-5</code></li>
</ul>

<p>Now the flame graph is obvious:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/filtering-2.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/filtering-2.png" alt="alt text" title="flames"></p>

<p>We can check this for a few more requests and figure out the following:</p>

<ul>
  <li>In every slow request, we executed <code class="language-plaintext highlighter-rouge">matrixMultiplySlow()</code></li>
  <li>In every fast request, we executed <code class="language-plaintext highlighter-rouge">matrixMultiplyFaster()</code></li>
</ul>

<p>This technique is great for dealing with the tail of the latency: We can focus our work on the longest
operations. That may lead us to some nice fixes.</p>

<h3 id="single-req-dns">Real-life example - DNS</h3>

<p>The point of the previous example was to show you why aggregated results can be useless for tracing
a single request. Now I want to show you a widespread issue I have diagnosed a few times.</p>

<p>Spring Boot has a commonly used addition called Actuator. One of the
features of the Actuator is the health check endpoint. Under URI <code class="language-plaintext highlighter-rouge">/actuator/health</code>, you can get JSON
with information about the health of your application. That endpoint is sometimes used as a load
balancer probe. Let’s consider a multi-node cluster of our example application with a load
balancer in front of the cluster, which:</p>

<ul>
  <li>probes the actuator if the application is alive, expecting <code class="language-plaintext highlighter-rouge">"status" : "UP"</code> in the response JSON</li>
  <li>timeouts the probe after <strong>1 second</strong></li>
</ul>

<p>Now, I will do one hack in my local configuration to make this example work. It will be explained at the end
of this example.</p>

<p>Let’s find out what our IP is:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ifconfig 

eth0: <span class="nv">flags</span><span class="o">=</span>4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9001
        inet 172.31.36.53  netmask 255.255.240.0  broadcast 172.31.47.255
</code></pre></div></div>

<p>Let’s probe an actuator by this IP, not a <code class="language-plaintext highlighter-rouge">localhost</code> (without the hack described later, you cannot get the same results):</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./profiler.sh start <span class="nt">-e</span> wall <span class="nt">-f</span> actuator.jfr first-application-0.0.1-SNAPSHOT.jar
ab <span class="nt">-n</span> 1000 http://172.31.36.53:8081/actuator/health <span class="c"># check your IP</span>
./profiler.sh stop <span class="nt">-f</span> actuator.jfr first-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>The result of <code class="language-plaintext highlighter-rouge">ab</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:     0    5 158.1      0    5000
Waiting:        0    5 158.1      0    5000
Total:          0    5 158.1      0    5000

Percentage of the requests served within a specific <span class="nb">time</span> <span class="o">(</span>ms<span class="o">)</span>
  50%      0
  66%      0
  75%      0
  80%      0
  90%      0
  95%      0
  98%      0
  99%      1
 100%   5000 <span class="o">(</span>longest request<span class="o">)</span>
</code></pre></div></div>

<p>So almost all the actuator endpoints returned in <strong>0ms</strong>, but at least one lasted <strong>5s</strong>.
We can see one longer request in the access logs:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>08/DEC/2022:08:56:24 +0000] <span class="o">[</span>GET /actuator/health HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>0 ms] <span class="o">[</span>http-nio-8081-exec-7]
<span class="o">[</span>08/DEC/2022:08:56:24 +0000] <span class="o">[</span>GET /actuator/health HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>0 ms] <span class="o">[</span>http-nio-8081-exec-10]
<span class="o">[</span>08/DEC/2022:08:56:24 +0000] <span class="o">[</span>GET /actuator/health HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>0 ms] <span class="o">[</span>http-nio-8081-exec-3]
<span class="o">[</span>08/DEC/2022:08:56:24 +0000] <span class="o">[</span>GET /actuator/health HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>0 ms] <span class="o">[</span>http-nio-8081-exec-2]
<span class="o">[</span>08/DEC/2022:08:56:29 +0000] <span class="o">[</span>GET /actuator/health HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>4999 ms] <span class="o">[</span>http-nio-8081-exec-8]
<span class="o">[</span>08/DEC/2022:08:56:29 +0000] <span class="o">[</span>GET /actuator/health HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>0 ms] <span class="o">[</span>http-nio-8081-exec-5]
</code></pre></div></div>

<p>That <strong>5s</strong> response would make our load balancer remove that node (for some time) from a cluster. Let’s
use the same technique to find out what was the reason for that latency:
(<a href="https://krzysztofslusarski.github.io/assets/async-demos/actuator.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/actuator.png" alt="alt text" title="flames"></p>

<p>I highlighted the usage of the <code class="language-plaintext highlighter-rouge">RemoteIpFilter</code> class. Time for some explanations: When your requests are hitting 
your application, you can check the IP of the requester with the basic <code class="language-plaintext highlighter-rouge">HttpServletRequest</code> API. But if you have
a load balancer before your application, well, you get an IP of the load balancer, not the original requester.
Load balancers usually add HTTP headers to the request to avoid such confusion. The original IP is sent
in the <code class="language-plaintext highlighter-rouge">X-Forwarded-For</code> header. The <code class="language-plaintext highlighter-rouge">RemoteIpFilter</code> is a tool that makes our lives easier and makes the
<code class="language-plaintext highlighter-rouge">HttpServletRequest</code> API returns proper IP and so on.</p>

<p>Let’s get back to the flame graph. We can see that this filter creates an instance of <code class="language-plaintext highlighter-rouge">XForwardedRequest</code> 
that executes <code class="language-plaintext highlighter-rouge">RequestFacade.getLocalName()</code>, that in the end executes <code class="language-plaintext highlighter-rouge">Inet6AddressImpl.getHostByAddr()</code>.
The last method is trying to identify the hostname by the IP address. How can it be done? Well, we just need a 
request to DNS, nothing more. In that case, the DNS protocol uses UDP, not TCP. UDP is a protocol that, by design,
can lose packets. In Linux, the <code class="language-plaintext highlighter-rouge">resolv.conf</code> is responsible for configuring DNS and the related tools
deal with all the retransmissions and other problems.
Here is an excerpt of the <a href="https://www.man7.org/linux/man-pages/man5/resolv.conf.5.html" target="_blank">manual</a>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>timeout:n
       Sets  the amount of time the resolver will wait for a re‐
       sponse from a remote  name  server  before  retrying  the
       query  via  a different name server.  This may not be the
       total time taken by any resolver API call and there is no
       guarantee  that a single resolver API call maps to a sin‐
       gle  timeout.   Measured  in  seconds,  the  default   is
       RES_TIMEOUT (currently 5, see &lt;resolv.h&gt;).  The value for
       this option is silently capped to 30.
</code></pre></div></div>

<p>Long story short - the default timeout is <strong>5s</strong>. If your DNS request is lost, the tools related to <code class="language-plaintext highlighter-rouge">resolv.conf</code> will probe the next
<em>nameserver</em> after <strong>5s</strong>. That’s what is happening in our example and what I observed in quite a few Java applications. 
DNS is commonly used for DDoS attacks. Therefore you can easily have a firewall in your 
infrastructure that can drop some DNS packets by design.</p>

<p>The funny thing about <code class="language-plaintext highlighter-rouge">RemoteIpFilter</code> is that the result of that DNS probing is stored in the field <code class="language-plaintext highlighter-rouge">localName</code> which 
is not used later. So we are just making DNS requests for nothing. To avoid that problem, write
a filter that won’t fire DNS requests. <code class="language-plaintext highlighter-rouge">RemoteIpFilter</code> is open-source, so you can easily use it.
There is also <code class="language-plaintext highlighter-rouge">RemoteIpValve</code> that can be enabled by just an entry in the Spring Boot properties. It used
to have the same issue. I didn’t check if the issue is still present in Spring Boot 3; it might be fixed accidentally
with <a href="https://bz.apache.org/bugzilla/show_bug.cgi?id=57665" target="_blank">this bug fix</a> which introduced the
<code class="language-plaintext highlighter-rouge">changeLocalName</code> property. If you want to be sure, you need to check it yourself.</p>

<p>This is not the only DNS request that can be done 
by the Actuator health check. That endpoint also probes your databases, 
queues, and many other things. The same may happen if that probing
is done by DNS name.</p>

<p>About the hack. If you want to simulate not responsive DNS, you can add 72.66.115.13 (blackhole.webpagetest.org) 
as your nameserver. That one is designed to drop all the packets. On different Linux distributions, it is done differently. 
I just use an AWS instance with Amazon Linux distribution, and there I could just edit the <code class="language-plaintext highlighter-rouge">/etc/resolv.conf</code> file, but 
in distros like Ubuntu, that file is generated by other services; see <a href="https://ubuntu.com/server/docs/service-domain-name-service-dns" target="_blank">ubuntu.com</a> for more information.</p>

<h2 id="continuous">Continuous profiling</h2>

<p>Let’s now focus on a different problem: We had some performance degradation/outage in our system one hour ago.
What can we do? The problem is gone, so attaching a profiler now won’t help us much. We can start profiling 
and wait for the problem to occur again, but maybe we can inspire ourselves with a concept used
in the aviation business.</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cont-1.png" alt="alt text" title="cont"></p>

<p>In case of an airplane disaster, what is the plane owner doing? Are 
they adding logs or attaching instruments to the airplane and waiting 
for the next crash? No, the aviation business has a flight recorder on 
every plane.</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cont-2.png" alt="alt text" title="cont"></p>

<p>This box records all available data it can during the flight. After any disaster, the data are ready to be analyzed.
Can we apply a similar approach to Java profiling? Yes, we can. We can have a profiler attached 24/7 dumping the data
every fixed interval of time. If anything detrimental happens to our application, we have the data that we can analyze.</p>

<p>From my personal experience, continuous profiling is the best 
technique to diagnose degradations
and outages efficiently. It is also handy to understand why the 
performance differs
between two versions of the same application. You only need to get 
profiles of the previous version from your archives and compare them to 
the current one.</p>

<p>Here are the ways of enabling async-profiler in continuous mode:</p>

<h3 id="continuous-bash">Command line</h3>

<p>Here is the simplest way to run async-profiler in continuous mode (dump a profile every <strong>60 seconds</strong> in <strong>wall</strong> mode):</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while </span><span class="nb">true
</span><span class="k">do
	</span><span class="nv">CURRENT_DATE</span><span class="o">=</span><span class="sb">`</span><span class="nb">date</span> +%F_%T<span class="sb">`</span>
	./profiler.sh <span class="nt">-e</span> wall <span class="nt">-f</span> out-<span class="nv">$CURRENT_DATE</span>.jfr <span class="nt">-d</span> 60 &lt;pid or application name&gt; 
<span class="k">done</span>
</code></pre></div></div>

<p>It looks dirt simple because it is, but I used that loop many times. Async-profiler includes this with the <code class="language-plaintext highlighter-rouge">--loop</code> option since version 2.6 in its <code class="language-plaintext highlighter-rouge">profiler.sh</code> script:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./profiler.sh <span class="nt">-e</span> wall <span class="nt">--loop</span> 1m <span class="nt">-f</span> profile-%t.jfr &lt;pid or application name&gt;
</code></pre></div></div>

<h3 id="continuous-java">Java</h3>

<p>I already introduced the Java API of AsyncProfiler <a href="#how-to-java">here</a>. To do it continuously, you can create a thread
that is executing:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">AsyncProfiler</span> <span class="n">asyncProfiler</span> <span class="o">=</span> <span class="nc">AsyncProfiler</span><span class="o">.</span><span class="na">getInstance</span><span class="o">();</span>

<span class="nc">DateTimeFormatter</span> <span class="n">formatter</span> <span class="o">=</span> <span class="nc">DateTimeFormatter</span><span class="o">.</span><span class="na">ofPattern</span><span class="o">(</span><span class="s">"yyyy-MM-dd_HH:mm:ss"</span><span class="o">);</span>

<span class="k">while</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">String</span> <span class="n">date</span> <span class="o">=</span> <span class="n">formatter</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="nc">LocalDateTime</span><span class="o">.</span><span class="na">now</span><span class="o">());</span>
    <span class="n">asyncProfiler</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span>
        <span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"start,jfr,event=wall,file=out-%s.jfr"</span><span class="o">,</span> <span class="n">date</span><span class="o">)</span>
    <span class="o">);</span>
    <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">60</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">);</span>
    <span class="n">asyncProfiler</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span>
        <span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"stop,file=out-%s.jfr"</span><span class="o">,</span> <span class="n">date</span><span class="o">)</span>
    <span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<h3 id="continuous-spring">Spring boot</h3>

<p>If you have a Spring/SpringBoot application, you can use a starter written by Michał Rowicki and me:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>com.github.krzysztofslusarski<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>continuous-async-profiler-spring-starter<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>2.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>Read the <strong><a href="https://github.com/krzysztofslusarski/continuous-async-profiler" target="_blank">README</a></strong> to get more details.</p>

<h2 id="context-id">Contextual profiling</h2>

<p>Continuous profiling, together with the possibility to extract a profile of a single request, is very
powerful. Unfortunately, there are applications where that is not enough. Some examples:</p>

<ul>
  <li>Any work that is delegated to a different thread will be missed in that profile</li>
  <li>If one request is computed by multiple threads/JVMs, we need to combine multiple profiles</li>
  <li>Applications in a distributed architecture, usually with microservices:<br>
There are usually remote calls to other services, even if every single request is processed by a single thread.</li>
</ul>

<p>We can extract a profile for each microservice to understand the 
request processing behavior in such a distributed architecture. This is 
doable but consumes a lot of time.</p>

<p>All the problems mentioned above can be covered by <strong>contextual profiling</strong>. The concept is pretty simple:
Whenever any thread is executing any work, that work is done in some context, usually in the context
of a single request. Instead of just doing that work, we do the following:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">asyncProfiler</span><span class="o">.</span><span class="na">setContextId</span><span class="o">(</span><span class="n">contextId</span><span class="o">);</span>
<span class="n">actualWork</span><span class="o">();</span>
<span class="n">asyncProfiler</span><span class="o">.</span><span class="na">clearContextId</span><span class="o">();</span>
</code></pre></div></div>

<p>If any sample is gathered during <code class="language-plaintext highlighter-rouge">actualWork()</code>, the profiler can add <code class="language-plaintext highlighter-rouge">contextId</code> to 
the sample in the JFR file. Such functionality is introduced in
<a href="https://github.com/jvm-profiling-tools/async-profiler/pull/576" target="_blank">Context ID PR</a>.
For now that PR is not merged into master, but it’s a matter of paperwork; I hope it will be
merged soon.</p>

<h3 id="context-id-spring">Spring Boot microservices</h3>

<p>Let’s try to join Spring Boot microservices with contextual profiling. In Spring Boot 3.0
we have included <strong>Micrometer Tracing</strong>. One of its functionalities is generating a <strong>context ID</strong> 
(called <code class="language-plaintext highlighter-rouge">traceId</code>) for every request. That <code class="language-plaintext highlighter-rouge">traceId</code> is passed during the execution to
other Spring Boot microservices. We just need to pass that <code class="language-plaintext highlighter-rouge">traceId</code> to the async-profiler
and we are done.</p>

<p>Since that PR is not merged into master, you need to compile the async-profiler from sources.
I compiled it on my Ubuntu x86 with glibc
<a href="https://github.com/krzysztofslusarski/async-profiler-demos/blob/master/libasyncProfiler.so" target="_blank">here</a>.
It may not work on every Linux on every machine. If this is your case, just compile the
profiler from sources. It’s straightforward.</p>

<p>Ok, let’s integrate it with the async-profiler. This time I will use the Java API:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">AsyncProfilerUtils</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">volatile</span> <span class="nc">AsyncProfiler</span> <span class="n">asyncProfiler</span><span class="o">;</span>
    <span class="c1">// ...</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="nc">AsyncProfiler</span> <span class="nf">load</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// Lazy load with double-checked locking</span>
        <span class="k">return</span> <span class="n">asyncProfiler</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">(</span><span class="nc">String</span> <span class="n">filename</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
        <span class="n">load</span><span class="o">().</span><span class="na">execute</span><span class="o">(</span><span class="s">"start,jfr,event=wall,file="</span> <span class="o">+</span> <span class="n">filename</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">stop</span><span class="o">(</span><span class="nc">String</span> <span class="n">filename</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
        <span class="n">load</span><span class="o">().</span><span class="na">execute</span><span class="o">(</span><span class="s">"stop,jfr,event=wall,file="</span> <span class="o">+</span> <span class="n">filename</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>I load the profiler from <code class="language-plaintext highlighter-rouge">/tmp/libasyncProfiler.so</code> and use <strong>wall-clock</strong> mode; I believe it is the
most suitable mode for most enterprise applications.</p>

<p>To integrate the profiler with the Micrometer Tracing, we need to implement <code class="language-plaintext highlighter-rouge">ObservationHandler</code>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AsyncProfilerObservationHandler</span> <span class="kd">implements</span> <span class="nc">ObservationHandler</span><span class="o">&lt;</span><span class="nc">Observation</span><span class="o">.</span><span class="na">Context</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="nc">ThreadLocal</span><span class="o">&lt;</span><span class="nc">TraceContext</span><span class="o">&gt;</span> <span class="no">LOCAL_TRACE_CONTEXT</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ThreadLocal</span><span class="o">&lt;&gt;();</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">supportsContext</span><span class="o">(</span><span class="nc">Observation</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="kc">true</span><span class="o">;</span> <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onStart</span><span class="o">(</span><span class="nc">Observation</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">TracingContext</span> <span class="n">tracingContext</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="nc">TracingContext</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
        <span class="nc">TraceContext</span> <span class="n">traceContext</span> <span class="o">=</span> <span class="n">tracingContext</span><span class="o">.</span><span class="na">getSpan</span><span class="o">().</span><span class="na">context</span><span class="o">();</span>
        <span class="nc">TraceContext</span> <span class="n">currentTraceContext</span> <span class="o">=</span> <span class="no">LOCAL_TRACE_CONTEXT</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>

        <span class="k">if</span> <span class="o">(</span><span class="n">currentTraceContext</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> 
                <span class="o">!</span><span class="n">currentTraceContext</span><span class="o">.</span><span class="na">traceId</span><span class="o">().</span><span class="na">equals</span><span class="o">(</span><span class="n">traceContext</span><span class="o">.</span><span class="na">traceId</span><span class="o">()))</span> <span class="o">{</span>
            <span class="no">LOCAL_TRACE_CONTEXT</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">traceContext</span><span class="o">);</span>
            <span class="nc">AsyncProfilerUtils</span><span class="o">.</span><span class="na">load</span><span class="o">().</span><span class="na">setContextId</span><span class="o">(</span><span class="n">lowerHexToUnsignedLong</span><span class="o">(</span><span class="n">traceContext</span><span class="o">.</span><span class="na">traceId</span><span class="o">()));</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onError</span><span class="o">(</span><span class="nc">Observation</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span> <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onEvent</span><span class="o">(</span><span class="nc">Observation</span><span class="o">.</span><span class="na">Event</span> <span class="n">event</span><span class="o">,</span> <span class="nc">Observation</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span> <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onStop</span><span class="o">(</span><span class="nc">Observation</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">TracingContext</span> <span class="n">tracingContext</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="nc">TracingContext</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
        <span class="nc">TraceContext</span> <span class="n">traceContext</span> <span class="o">=</span> <span class="n">tracingContext</span><span class="o">.</span><span class="na">getSpan</span><span class="o">().</span><span class="na">context</span><span class="o">();</span>
        <span class="nc">TraceContext</span> <span class="n">currentTraceContext</span> <span class="o">=</span> <span class="no">LOCAL_TRACE_CONTEXT</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
        
        <span class="k">if</span> <span class="o">(</span><span class="n">currentTraceContext</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">&amp;&amp;</span> 
                <span class="n">currentTraceContext</span><span class="o">.</span><span class="na">spanId</span><span class="o">().</span><span class="na">equals</span><span class="o">(</span><span class="n">traceContext</span><span class="o">.</span><span class="na">spanId</span><span class="o">()))</span> <span class="o">{</span>
            <span class="no">LOCAL_TRACE_CONTEXT</span><span class="o">.</span><span class="na">remove</span><span class="o">();</span>
            <span class="nc">AsyncProfilerUtils</span><span class="o">.</span><span class="na">load</span><span class="o">().</span><span class="na">clearContextId</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p><strong>Big warning</strong>: Don’t treat that class as production ready. It’s suitable for that example
but will not work with any asynchronous/reactive calls. Mind that <code class="language-plaintext highlighter-rouge">onStart/onStop</code>
can be called multiple times with the same <code class="language-plaintext highlighter-rouge">traceId</code> and different <code class="language-plaintext highlighter-rouge">spanId</code>.</p>

<p>Now we need to register that implementation:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="nd">@Profile</span><span class="o">(</span><span class="s">"context"</span><span class="o">)</span>
<span class="nc">ObservedAspect</span> <span class="nf">observedAspect</span><span class="o">(</span><span class="nc">ObservationRegistry</span> <span class="n">observationRegistry</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">observationRegistry</span><span class="o">.</span><span class="na">observationConfig</span><span class="o">().</span><span class="na">observationHandler</span><span class="o">(</span><span class="k">new</span> <span class="nc">AsyncProfilerObservationHandler</span><span class="o">());</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nf">ObservedAspect</span><span class="o">(</span><span class="n">observationRegistry</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>That will also register us using the <code class="language-plaintext highlighter-rouge">@Observed</code> aspect.</p>

<p>And that’s it. Let’s try it out. We need to rerun the Spring Boot applications with active profiling:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="se">\</span>
<span class="nt">-Dspring</span>.profiles.active<span class="o">=</span>context <span class="se">\</span>
<span class="nt">-XX</span>:+UnlockDiagnosticVMOptions <span class="nt">-XX</span>:+DebugNonSafepoints <span class="se">\</span>
<span class="nt">-jar</span> first-application/target/first-application-0.0.1-SNAPSHOT.jar 

java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="se">\</span>
<span class="nt">-Dspring</span>.profiles.active<span class="o">=</span>context <span class="se">\</span>
<span class="nt">-jar</span> second-application/target/second-application-0.0.1-SNAPSHOT.jar

java <span class="nt">-Xms1G</span> <span class="nt">-Xmx1G</span> <span class="se">\</span>
<span class="nt">-Dspring</span>.profiles.active<span class="o">=</span>context <span class="se">\</span>
<span class="nt">-jar</span> third-application/target/third-application-0.0.1-SNAPSHOT.jar
</code></pre></div></div>

<p>Now the applications will look for an async-profiler in <code class="language-plaintext highlighter-rouge">/tmp/libasyncProfiler.so</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># little warmup</span>
ab <span class="nt">-n</span> 24 <span class="nt">-c</span> 1 http://localhost:8081/examples/context/observe

<span class="c"># profiling time - this time, we start profiler from Java</span>
curl <span class="nt">-v</span> http://localhost:8081/examples/context/start
curl <span class="nt">-v</span> http://localhost:8082/examples/context/start
curl <span class="nt">-v</span> http://localhost:8083/examples/context/start

ab <span class="nt">-n</span> 24 <span class="nt">-c</span> 1 http://localhost:8081/examples/context/observe

<span class="c"># stopping the profiler</span>
curl <span class="nt">-v</span> http://localhost:8081/examples/context/stop
curl <span class="nt">-v</span> http://localhost:8082/examples/context/stop
curl <span class="nt">-v</span> http://localhost:8083/examples/context/stop
</code></pre></div></div>

<p>Let’s look at the timings during profiling. I’ve cut the output to 12 rows:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>04/gru/2022:20:54:25 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1538 ms] <span class="o">[</span>http-nio-8081-exec-8]
04/gru/2022:20:54:26 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1537 ms] <span class="o">[</span>http-nio-8081-exec-9]
04/gru/2022:20:54:29 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>3039 ms] <span class="o">[</span>http-nio-8081-exec-10]
04/gru/2022:20:54:33 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>3218 ms] <span class="o">[</span>http-nio-8081-exec-1]
04/gru/2022:20:54:34 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1538 ms] <span class="o">[</span>http-nio-8081-exec-2]
04/gru/2022:20:54:37 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>3038 ms] <span class="o">[</span>http-nio-8081-exec-3]
04/gru/2022:20:54:39 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1538 ms] <span class="o">[</span>http-nio-8081-exec-4]
04/gru/2022:20:54:42 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>3270 ms] <span class="o">[</span>http-nio-8081-exec-5]
04/gru/2022:20:54:45 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>3038 ms] <span class="o">[</span>http-nio-8081-exec-6]
04/gru/2022:20:54:47 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1536 ms] <span class="o">[</span>http-nio-8081-exec-7]
04/gru/2022:20:54:48 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>1536 ms] <span class="o">[</span>http-nio-8081-exec-8]
04/gru/2022:20:54:53 +0100 <span class="o">[</span>GET /examples/context/observe HTTP/1.0] <span class="o">[</span>200] <span class="o">[</span>4756 ms] <span class="o">[</span>http-nio-8081-exec-9]
</code></pre></div></div>

<p>We can see that we have three groups of timings:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">~1500ms</code></li>
  <li><code class="language-plaintext highlighter-rouge">~3000ms</code></li>
  <li><code class="language-plaintext highlighter-rouge">~4500ms</code></li>
</ul>

<p>After we executed the script above, we had three JFR files in the <code class="language-plaintext highlighter-rouge">/tmp</code> directory. When we load all three files 
together to my viewer and check the <em>Correlation ID stats</em> section, we can see:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/context-1.png" alt="alt text" title="context-1"></p>

<p>So we have similar timings from our JFR files. Looking good. Let’s filter all the samples by context ID. It’s
called a <em>Correlation ID filter</em> in my viewer, let’s use a value <code class="language-plaintext highlighter-rouge">-3264552494855344825</code> which took <code class="language-plaintext highlighter-rouge">4650ms</code> 
according to records in the JFR. Let’s also add an additional <em>filename level</em>. The filename is correlated to
the application name. Here comes the flame graph: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/context-1.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/context-2.png" alt="alt text" title="flames"></p>

<p>All three applications are on the same flame graph. This is beautiful. Just a reminder: it’s not a whole application. It’s a <strong>single request</strong> presented here. I highlighted the <code class="language-plaintext highlighter-rouge">slowPath()</code> method
executed in the second and third app, which causes higher latency. You can play with the HTML flame graph 
to see what is happening there or jump into the code. I want to focus on what insights the context ID 
functionality gives us. Because there is more. We’ve already added an additional <em>filename level</em>. We can also
add timestamps as another level. Let’s do that. I will present you only the bottom of the graph since
that’s what is important here: (<a href="https://krzysztofslusarski.github.io/assets/async-demos/context-2.html" target="_blank">HTML</a>)</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/context-3.png" alt="alt text" title="flames"></p>

<p>The image may look blurred, but you can check the <a href="https://krzysztofslusarski.github.io/assets/async-demos/context-2.html" target="_blank">HTML</a>
version for clarity. At the bottom, you can see five brown rectangles. Those are timestamps truncated to seconds.
So from left to right, we can see what was happening to our request second by second. Let’s highlight
when the second application was running during that request:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/context-4.png" alt="alt text" title="flames"></p>

<p>And the third:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/context-5.png" alt="alt text" title="flames"></p>

<p>The first application is always running since it’s the entry point to
 our distributed architecture. The important code in the second 
application
is the following:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@RequiredArgsConstructor</span>
<span class="kd">class</span> <span class="nc">ContextService</span> <span class="o">{</span>
    <span class="c1">// ...</span>
    <span class="kt">void</span> <span class="nf">doSomething</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">counter</span><span class="o">.</span><span class="na">incrementAndGet</span><span class="o">()</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slowPath</span><span class="o">();</span>
            <span class="k">return</span><span class="o">;</span>
        <span class="o">}</span>

        <span class="n">fastPath</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">fastPath</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// ...</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">slowPath</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// ...</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>And the third application:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">ContextService</span> <span class="o">{</span>
    <span class="c1">// ...</span>
    <span class="kt">void</span> <span class="nf">doSomething</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">counter</span><span class="o">.</span><span class="na">incrementAndGet</span><span class="o">()</span> <span class="o">%</span> <span class="mi">4</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">blackhole</span> <span class="o">=</span> <span class="n">slowPath</span><span class="o">();</span>
            <span class="k">return</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="n">blackhole</span> <span class="o">=</span> <span class="n">fastPath</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">int</span> <span class="nf">slowPath</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// ...</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">int</span> <span class="nf">fastPath</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// ...</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>So the second application is slower every third request, and the third application is slower every fourth request.
That means that for every twelfth request, we are slower in both of them.</p>

<p>I firmly believe that contextual profiling is the future in that area. Everything you see here should be taken with a grain of
salt. My Spring integration and my JFR viewer are far away from something professional. I want to inspire you to
search for new possibilities like that. If you find any, share it with the rest of the Java performance community.</p>

<h3 id="context-id-hz">Distributed systems</h3>

<p>First, let’s differentiate distributed architecture from distributed systems. For this post, let’s assume
the following:</p>

<ul>
  <li>a distributed architecture is a set of applications that works together - like microservices</li>
  <li>a distributed system is one application that is deployed on more than one JVM to service some request
it distributes the work to more than one instance</li>
</ul>

<p>One example of a distributed system may be Hazelcast. I’ve applied the context ID functionality to trace the tail of
the latency in SQL queries.</p>

<p>Sample benchmark details:</p>

<ul>
  <li>Hazelcast cluster size: <strong>4</strong></li>
  <li>Servers with <strong>Intel Xeon CPU E5-2687W</strong></li>
  <li>Heap size: <strong>10 GB</strong></li>
  <li><strong>JDK17</strong></li>
  <li>SQL query that is benchmarked: <code class="language-plaintext highlighter-rouge">select count(*) from iMap</code></li>
  <li>iMap size – <strong>1 million</strong> serialized Java objects</li>
  <li>Benchmark duration: <strong>8 minutes</strong></li>
</ul>

<p>The latency distribution for that benchmark is:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/dist.png" alt="alt text" title="dist"></p>

<p>The <strong>50th</strong> percentile is <strong>1470 ms</strong>, whereas the <strong>99.9th</strong> is <strong>3718 ms</strong>. 
Let’s now analyze the <strong>JFR</strong> file with my tool.
I’ve created a table with the longest queries in the files:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/cid.png" alt="alt text" title="cid"></p>

<p>Let’s analyze a single query using the context ID functionality. The full flame graph:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/1_002.png" alt="alt text" title="1"></p>

<p>Let’s focus on the bottom rows:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/2_002.png" alt="alt text" title="2"></p>

<p>Let’s start with timestamps and highlight them one by one:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/3_002.png" alt="alt text" title="3">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/4_002.png" alt="alt text" title="4">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/5.png" alt="alt text" title="5">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/6.png" alt="alt text" title="6">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/7.png" alt="alt text" title="7"></p>

<p>Summing that up:</p>

<ul>
  <li><strong>41.91%</strong> of samples were gathered between 14:47:19 and 14:47:20</li>
  <li><strong>35.79%</strong> of samples were gathered between 14:47:20 and 14:47:21</li>
  <li><strong>6.68%</strong> of samples were gathered between 14:47:21 and 14:47:22</li>
  <li><strong>12.37%</strong> of samples were gathered between 14:47:22 and 14:47:23</li>
  <li><strong>3.34%</strong> of samples were gathered between 14:47:23 and 14:47:24</li>
</ul>

<p>Let’s highlight the filenames (which are named with the <strong>IP</strong> of the server) one by one:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/8.png" alt="alt text" title="8">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/9.png" alt="alt text" title="9">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/10.png" alt="alt text" title="10">
<img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/11.png" alt="alt text" title="11"></p>

<p>A little summary:</p>

<ul>
  <li><strong>25.42%</strong> of samples are from node 10.212.1.101</li>
  <li><strong>23,75%</strong> of samples are from node 10.212.1.102</li>
  <li><strong>21.07%</strong> of samples are from node 10.212.1.103</li>
  <li><strong>29.77%</strong> of samples are from node 10.212.1.104</li>
</ul>

<p>Since brown bars are sorted alphabetically by timestamps, we can conclude that the <strong>10.212.1.104</strong> server is doing any work
in the last seconds of processing.</p>

<p>I checked five more long latency requests and the results were the same, confirming that the <strong>10.212.1.104</strong> server is 
the problem. I spent a lot of time trying to figure out what was wrong with that machine. My biggest suspect was a 
difference in meltdown/spectre patches in the kernel. In the end, we reinstalled Linux on those machines, which solved
the problem with the <strong>10.212.1.104</strong> server.</p>

<h2 id="stability">Stability</h2>

<p>Attaching a profiler to a JVM can potentially cause it to crash. It’s
 essential to be aware of this risk, as bugs can occur not only in 
profilers but also in the JVM itself. The OpenJDK developers are working
 on improving the stability of the API used by profilers to minimize 
this risk. You can learn more about their work at:</p>

<ul>
  <li><a href="https://github.com/openjdk/jdk/pulls?q=is%3Apr+author%3Aparttimenerd" target="_blank">Johannes Bechberger</a></li>
  <li><a href="https://github.com/openjdk/jdk/pulls?q=is%3Apr+author%3Ajbachorik" target="_blank">Jaroslav Bachorik</a></li>
</ul>

<p>In my opinion, async-profiler is a very mature product already. I 
know a few companies
that are running async-profiler in continuous mode 24/7. Over two years,
 I only heard about one production crash caused by a profiler. It is 
working with <strong>40</strong> production JVMs, at least in wall-clock
 mode there. I have used async-profiler on multiple systems without 
crashes this year. While there is always some risk when attaching a 
profiler to a JVM, I believe the risk is minimal and can be safely 
ignored.</p>

<p>However, if you experience a profiler-related crash, I encourage you to file a GitHub issue to help improve the OpenJDK.
During the crash, the <code class="language-plaintext highlighter-rouge">hs_err.&lt;pid&gt;</code> file is generated. It may be beneficial for finding the root cause of a problem.</p>

<p>The main problem, according to Johannes Bechberger, stated in a recent <a href="https://openjdk.org/jeps/435" target="_blank">JEP proposal</a>,
 is that async-profiler uses the internal AsyncGetCallTrace API for 
stack walking. This API was introduced in November 2002 for Sun Studio 
but was removed in January 2003 and demoted to an internal API (<a href="https://docs.oracle.com/en/java/javase/17/docs/specs/jvmti.html#ChangeHistory" target="_blank">JVMTI</a>). It is neither exported in any header nor standardized. To this date, there is only one <a href="https://github.com/openjdk/jdk/tree/master/test/hotspot/jtreg/serviceability/AsyncGetCallTrace" target="_blank">tiny test</a> in the whole OpenJDK: The API might be broken with any version, Johannes Bechberger caught such an issue with <a href="https://github.com/openjdk/jdk/pull/7559" target="_blank">PR 7559</a> before the release. Be aware of this risk and test every JDK with your profiling setup before using it in production.</p>

<p>There is an ongoing effort by Johannes Bechberger, with the help of 
Jaroslav Bachorik and others, to improve this situation by proposing the
 new <a href="https://openjdk.org/jeps/435" target="_blank">AsyncGetStackTrace API</a>,
 that will hopefully be integrated into the OpenJDK. This API will be 
official, well-tested with stability and stress tests in the official 
OpenJDK test suite, and therefore more stable than AsyncGetCallTrace. It
 will also give the users of tools like async-profiler more information,
 like C/C++ frames between Java frames and inlining information for all 
Java frames. If you want to learn more, consider reading the <a href="https://openjdk.org/jeps/435" target="_blank">JEP</a> or visit the <a href="https://github.com/parttimenerd/asgct2-demo" target="_blank">demo repository</a> to see it in action.</p>

<p>Furthermore, many bugs have been found by both OpenJDK developers by using the <a href="https://github.com/parttimenerd/jdk-profiling-tester" target="_blank">JDK Profiling Tester</a> to find and fix many stability issues. There are currently no known real-world stability issues.</p>

<h2 id="overhead">Overhead</h2>

<p>In the application where the profiler is running in continuous mode on production the 
overhead (in terms of response time) is typically between <strong>0%</strong> and <strong>2%</strong>. That number is a comparison of response times 
before and after introducing continuous profiling there. A bit of context:</p>

<ul>
  <li>Spring and Spring Boot applications</li>
  <li>Mostly services that handle HTTP requests</li>
  <li>Not really CPU intensive - I would say that on average <strong>60%</strong> of the request time was spent off-CPU (waiting for DB/other service)</li>
  <li>JDK 11 and 17 - HotSpot from various vendors</li>
  <li>Wall-clock event, dump of JFR every minute from Java API</li>
  <li>Environment provided by VMware, both VMs and Tanzu clusters</li>
  <li>Async-profiler 1.8.x, later 2.8.x</li>
</ul>

<p>Johannes Bechberger shared his benchmark results with me. He used the
<a href="https://dacapobench.sourceforge.net/" target="_blank">DaCapo Benchmark Suite</a>:</p>

<ul>
  <li>ThreadRipper 3995WX with 128GB RAM</li>
  <li>Async-profiler 2.8.3</li>
  <li><code class="language-plaintext highlighter-rouge">dacapo benchmarks avrora fop h2 jython lusearch pmd -t 8 -n 3</code></li>
  <li>CPU event</li>
</ul>

<p>Johannes’s results shows <strong>~6%</strong> overhead on default sampling interval without <code class="language-plaintext highlighter-rouge">jfrsync</code> flag, and <strong>~7.5%</strong> with <code class="language-plaintext highlighter-rouge">jfrsync</code>. 
The chart for his results:</p>

<p><img src="[Java][Profiling]%20Async-profiler%20-%20manual%20by%20use%20cases%20_%20JVM_Java%20profiling%20and%20tuning_files/overhead.png" alt="alt text" title="chart"></p>

<p>The logarithmic-scaled X-axis is the number of samples per second, and the Y-axis is the additional overhead.</p>

<p>Remember: <strong>You should always measure the overhead in your 
application by yourself and configure the profiling interval and 
captured events according to your specific needs.</strong>.</p>

<h2 id="random">Random thoughts</h2>

<ol>
  <li>You need to remember that EVERY profiler lies in some way. The async-profiler is vulnerable to
<a href="https://bugs.openjdk.org/browse/JDK-8281677" target="_blank">JDK-8281677</a>. There is nothing that the profiler
can do; JVM is lying to the profiler, so that lie is passed to the end user. You can change the mechanism
used by a profiler, but you will be lied to, maybe differently.</li>
  <li>You can run an async-profiler to collect more than one event. It is allowed to gather <code class="language-plaintext highlighter-rouge">lock</code> and <code class="language-plaintext highlighter-rouge">alloc</code>
together with one of the modes that gathers execution samples, like <code class="language-plaintext highlighter-rouge">cpu</code>, <code class="language-plaintext highlighter-rouge">method</code>, …</li>
  <li>You can run an async-profiler with the <code class="language-plaintext highlighter-rouge">jfrsync</code> option that will gather more information exposed 
by the JVM, but be aware to use the <code class="language-plaintext highlighter-rouge">alloc</code> option for information on allocations. This way, you can also
capture GC information and more.</li>
</ol>

<p>If you want to know more on this topic, consider the curated collection of blogs and other resources you find <a href="https://github.com/parttimenerd/jug-profiling-talk" target="_blank">here</a> and the <a href="https://www.youtube.com/playlist?list=PLLLT4NxU7U1QYiqanOw48h0VUjlUvqCCv" target="_blank">YouTube playlist</a> with in-depth talks on profiling. Consider contacting Johannes Bechberger, who curates both, if you have any suggestions.</p>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
      </footer>
    </main>
  

</body></html>